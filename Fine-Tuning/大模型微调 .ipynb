{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3852b9f0",
   "metadata": {},
   "source": [
    "# å¾®è°ƒå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ba7ea",
   "metadata": {},
   "source": [
    "### 1 ä»€ä¹ˆæ˜¯ SFT\n",
    "\n",
    "é¢„è®­ç»ƒæ˜¯ LLM å¼ºå¤§èƒ½åŠ›çš„æ ¹æœ¬æ¥æºï¼Œäº‹å®ä¸Šï¼ŒLLM æ‰€è¦†ç›–çš„æµ·é‡çŸ¥è¯†åŸºæœ¬éƒ½æ˜¯æºäºé¢„è®­ç»ƒè¯­æ–™ã€‚LLM çš„æ€§èƒ½æœ¬èº«ï¼Œæ ¸å¿ƒä¹Ÿåœ¨äºé¢„è®­ç»ƒçš„å·¥ä½œã€‚ä½†æ˜¯ï¼Œé¢„è®­ç»ƒèµ‹äºˆäº† LLM èƒ½åŠ›ï¼Œå´è¿˜éœ€è¦ç¬¬äºŒæ­¥å°†å…¶æ¿€å‘å‡ºæ¥ã€‚ç»è¿‡é¢„è®­ç»ƒçš„ LLM å¥½åƒä¸€ä¸ªåšè§ˆç¾¤ä¹¦ä½†åˆä¸æ±‚ç”šè§£çš„ä¹¦ç”Ÿï¼Œå¯¹ä»€ä¹ˆæ ·çš„åæ€ªé—®é¢˜ï¼Œéƒ½å¯ä»¥æµç•…åœ°æ¥å‡ºä¸‹æ–‡ï¼Œä½†ä»–åååˆä¸çŸ¥é“é—®é¢˜æœ¬èº«çš„å«ä¹‰ï¼Œåªä¼šâ€œæ­»æ¿èƒŒä¹¦â€ã€‚è¿™ä¸€ç°è±¡çš„æœ¬è´¨æ˜¯å› ä¸ºï¼ŒLLM çš„é¢„è®­ç»ƒä»»åŠ¡å°±æ˜¯ç»å…¸çš„ CLMï¼Œä¹Ÿå°±æ˜¯è®­ç»ƒå…¶é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„èƒ½åŠ›ï¼Œåœ¨æ²¡æœ‰è¿›ä¸€æ­¥å¾®è°ƒä¹‹å‰ï¼Œå…¶æ— æ³•ä¸å…¶ä»–ä¸‹æ¸¸ä»»åŠ¡æˆ–æ˜¯ç”¨æˆ·æŒ‡ä»¤é€‚é…ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ç¬¬äºŒæ­¥æ¥æ•™è¿™ä¸ªåšè§ˆç¾¤ä¹¦çš„å­¦ç”Ÿå¦‚ä½•å»ä½¿ç”¨å®ƒçš„çŸ¥è¯†ï¼Œä¹Ÿå°±æ˜¯ SFTï¼ˆSupervised Fine-Tuningï¼Œæœ‰ç›‘ç£å¾®è°ƒï¼‰ã€‚æ‰€è°“æœ‰ç›‘ç£å¾®è°ƒï¼Œå…¶å®å°±æ˜¯æˆ‘ä»¬åœ¨ç¬¬ä¸‰ç« ä¸­è®²è¿‡çš„é¢„è®­ç»ƒ-å¾®è°ƒä¸­çš„å¾®è°ƒï¼Œç¨æœ‰åŒºåˆ«çš„æ˜¯ï¼Œå¯¹äºèƒ½åŠ›æœ‰é™çš„ä¼ ç»Ÿé¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦é’ˆå¯¹æ¯ä¸€ä¸ªä¸‹æ¸¸ä»»åŠ¡å•ç‹¬å¯¹å…¶è¿›è¡Œå¾®è°ƒä»¥è®­ç»ƒæ¨¡å‹åœ¨è¯¥ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ä¾‹å¦‚è¦è§£å†³æ–‡æœ¬åˆ†ç±»é—®é¢˜ï¼Œéœ€è¦å¯¹ BERT è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„å¾®è°ƒï¼›è¦è§£å†³å®ä½“è¯†åˆ«çš„é—®é¢˜ï¼Œå°±éœ€è¦è¿›è¡Œå®ä½“è¯†åˆ«ä»»åŠ¡çš„å¾®è°ƒã€‚\n",
    "\n",
    "è€Œé¢å¯¹èƒ½åŠ›å¼ºå¤§çš„ LLMï¼Œæˆ‘ä»¬å¾€å¾€ä¸å†æ˜¯åœ¨æŒ‡å®šä¸‹æ¸¸ä»»åŠ¡ä¸Šæ„é€ æœ‰ç›‘ç£æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œè€Œæ˜¯é€‰æ‹©è®­ç»ƒæ¨¡å‹çš„â€œé€šç”¨æŒ‡ä»¤éµå¾ªèƒ½åŠ›â€ï¼Œä¹Ÿå°±æ˜¯ä¸€èˆ¬é€šè¿‡`æŒ‡ä»¤å¾®è°ƒ`çš„æ–¹å¼æ¥è¿›è¡Œ SFTã€‚\n",
    "\n",
    "æ‰€è°“æŒ‡ä»¤å¾®è°ƒï¼Œå³æˆ‘ä»¬è®­ç»ƒçš„è¾“å…¥æ˜¯å„ç§ç±»å‹çš„ç”¨æˆ·æŒ‡ä»¤ï¼Œè€Œéœ€è¦æ¨¡å‹æ‹Ÿåˆçš„è¾“å‡ºåˆ™æ˜¯æˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨æ”¶åˆ°è¯¥æŒ‡ä»¤ååšå‡ºçš„å›å¤ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çš„ä¸€æ¡è®­ç»ƒæ ·æœ¬å¯ä»¥æ˜¯ï¼š\n",
    "\n",
    "    input:å‘Šè¯‰æˆ‘ä»Šå¤©çš„å¤©æ°”é¢„æŠ¥ï¼Ÿ\n",
    "    output:æ ¹æ®å¤©æ°”é¢„æŠ¥ï¼Œä»Šå¤©å¤©æ°”æ˜¯æ™´è½¬å¤šäº‘ï¼Œæœ€é«˜æ¸©åº¦26æ‘„æ°åº¦ï¼Œæœ€ä½æ¸©åº¦9æ‘„æ°åº¦ï¼Œæ˜¼å¤œæ¸©å·®å¤§ï¼Œè¯·æ³¨æ„ä¿æš–å“¦\n",
    "\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼ŒSFT çš„ä¸»è¦ç›®æ ‡æ˜¯è®©æ¨¡å‹ä»å¤šç§ç±»å‹ã€å¤šç§é£æ ¼çš„æŒ‡ä»¤ä¸­è·å¾—æ³›åŒ–çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œä¹Ÿå°±æ˜¯èƒ½å¤Ÿç†è§£å¹¶å›å¤ç”¨æˆ·çš„æŒ‡ä»¤ã€‚å› æ­¤ï¼Œç±»ä¼¼äº Pretrainï¼ŒSFT çš„æ•°æ®è´¨é‡å’Œæ•°æ®é…æ¯”ä¹Ÿæ˜¯å†³å®šæ¨¡å‹æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„é‡è¦å› ç´ ã€‚\n",
    "\n",
    "é¦–å…ˆæ˜¯æŒ‡ä»¤æ•°æ®é‡åŠè¦†ç›–èŒƒå›´ã€‚ä¸ºäº†ä½¿ LLM èƒ½å¤Ÿè·å¾—æ³›åŒ–çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå³èƒ½å¤Ÿåœ¨æœªè®­ç»ƒçš„æŒ‡ä»¤ä¸Šè¡¨ç°è‰¯å¥½ï¼Œéœ€è¦æ”¶é›†å¤§é‡ç±»åˆ«å„å¼‚çš„ç”¨æˆ·æŒ‡ä»¤å’Œå¯¹åº”å›å¤å¯¹ LLM è¿›è¡Œè®­ç»ƒã€‚ä¸€èˆ¬æ¥è¯´ï¼Œåœ¨å•ä¸ªä»»åŠ¡ä¸Š 500~1000 çš„è®­ç»ƒæ ·æœ¬å°±å¯ä»¥è·å¾—ä¸é”™çš„å¾®è°ƒæ•ˆæœã€‚ä½†æ˜¯ï¼Œä¸ºäº†è®© LLM è·å¾—æ³›åŒ–çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œåœ¨å¤šç§ä»»åŠ¡æŒ‡ä»¤ä¸Šè¡¨ç°è‰¯å¥½ï¼Œéœ€è¦åœ¨è®­ç»ƒæ•°æ®é›†ä¸­è¦†ç›–å¤šç§ç±»å‹çš„ä»»åŠ¡æŒ‡ä»¤ï¼ŒåŒæ—¶ä¹Ÿéœ€è¦ç›¸å¯¹è¾ƒå¤§çš„è®­ç»ƒæ•°æ®é‡ï¼Œè¡¨ç°è‰¯å¥½çš„å¼€æº LLM SFT æ•°æ®é‡ä¸€èˆ¬åœ¨æ•° B token å·¦å³ã€‚\n",
    "\n",
    "ä¸€èˆ¬ SFT æ‰€ä½¿ç”¨çš„æŒ‡ä»¤æ•°æ®é›†åŒ…æ‹¬ä»¥ä¸‹ä¸‰ä¸ªé”®ï¼š\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"instruction\":\"å³è¾“å…¥çš„ç”¨æˆ·æŒ‡ä»¤\",\n",
    "    \"input\":\"æ‰§è¡Œè¯¥æŒ‡ä»¤å¯èƒ½éœ€è¦çš„è¡¥å……è¾“å…¥ï¼Œæ²¡æœ‰åˆ™ç½®ç©º\",\n",
    "    \"output\":\"å³æ¨¡å‹åº”è¯¥ç»™å‡ºçš„å›å¤\"\n",
    "}\n",
    "```\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çš„æŒ‡ä»¤æ˜¯å°†ç›®æ ‡æ–‡æœ¬â€œä»Šå¤©å¤©æ°”çœŸå¥½â€ç¿»è¯‘æˆè‹±æ–‡ï¼Œé‚£ä¹ˆè¯¥æ¡æ ·æœ¬å¯ä»¥æ„å»ºæˆå¦‚ä¸‹å½¢å¼ï¼š\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"instruction\":\"å°†ä¸‹åˆ—æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\",\n",
    "    \"input\":\"ä»Šå¤©å¤©æ°”çœŸå¥½\",\n",
    "    \"output\":\"Today is a nice dayï¼\"\n",
    "}\n",
    "```\n",
    "\n",
    "åŒæ—¶ï¼Œä¸ºä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°å’Œé¢„è®­ç»ƒä¸åŒçš„èŒƒå¼ï¼Œåœ¨ SFT çš„è¿‡ç¨‹ä¸­ï¼Œå¾€å¾€ä¼šé’ˆå¯¹æ€§è®¾ç½®ç‰¹å®šæ ¼å¼ã€‚ä¾‹å¦‚ï¼ŒLLaMA çš„ SFT æ ¼å¼ä¸ºï¼š\n",
    "\n",
    "    ### Instruction:\\n{{content}}\\n\\n### Response:\\n\n",
    "\n",
    "å…¶ä¸­çš„ content å³ä¸ºå…·ä½“çš„ç”¨æˆ·æŒ‡ä»¤ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºæ¯ä¸€ä¸ªç”¨æˆ·æŒ‡ä»¤ï¼Œå°†ä¼šåµŒå…¥åˆ°ä¸Šæ–‡çš„ content éƒ¨åˆ†ï¼Œè¿™é‡Œçš„ç”¨æˆ·æŒ‡ä»¤ä¸ä»…æŒ‡ä¸Šä¾‹ä¸­çš„ â€œinstructionâ€ï¼Œè€Œæ˜¯æŒ‡ä»¤å’Œè¾“å…¥çš„æ‹¼æ¥ï¼Œå³æ¨¡å‹å¯ä»¥æ‰§è¡Œçš„ä¸€æ¡å®Œæ•´æŒ‡ä»¤ã€‚ä¾‹å¦‚ï¼Œé’ˆå¯¹ä¸Šä¾‹ï¼ŒLLaMA è·å¾—çš„è¾“å…¥åº”è¯¥æ˜¯ï¼š\n",
    "\n",
    "    ### Instruction:\\nå°†ä¸‹åˆ—æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼šä»Šå¤©å¤©æ°”çœŸå¥½\\n\\n### Response:\\n\n",
    "\n",
    "å…¶éœ€è¦æ‹Ÿåˆçš„è¾“å‡ºåˆ™æ˜¯ï¼š\n",
    "\n",
    "    ### Instruction:\\nå°†ä¸‹åˆ—æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼šä»Šå¤©å¤©æ°”çœŸå¥½\\n\\n### Response:\\nToday is a nice dayï¼\n",
    "\n",
    "æ³¨æ„ï¼Œå› ä¸ºæŒ‡ä»¤å¾®è°ƒæœ¬è´¨ä¸Šä»ç„¶æ˜¯å¯¹æ¨¡å‹è¿›è¡Œ CLM è®­ç»ƒï¼Œåªä¸è¿‡è¦æ±‚æ¨¡å‹å¯¹æŒ‡ä»¤è¿›è¡Œç†è§£å’Œå›å¤è€Œä¸æ˜¯ç®€å•åœ°é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼Œæ‰€ä»¥æ¨¡å‹é¢„æµ‹çš„ç»“æœä¸ä»…æ˜¯ outputï¼Œè€Œåº”è¯¥æ˜¯ input + outputï¼Œåªä¸è¿‡ input éƒ¨åˆ†ä¸å‚ä¸ loss çš„è®¡ç®—ï¼Œä½†å›å¤æŒ‡ä»¤æœ¬èº«è¿˜æ˜¯ä»¥é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„å½¢å¼æ¥å®ç°çš„ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d71257-3c1c-4303-8ff8-af161ebc2cf1",
   "metadata": {},
   "source": [
    "### 1.1 é«˜æ•ˆå¾®è°ƒ-LoRA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1e9e7",
   "metadata": {},
   "source": [
    "### 1.1.1 ä»€ä¹ˆæ˜¯é«˜æ•ˆå¾®è°ƒ\n",
    "\n",
    "é’ˆå¯¹å…¨é‡å¾®è°ƒçš„æ˜‚è´µé—®é¢˜ï¼Œç›®å‰ä¸»è¦æœ‰ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼š\n",
    "\n",
    "**Adapt Tuning**ã€‚å³åœ¨æ¨¡å‹ä¸­æ·»åŠ  Adapter å±‚ï¼Œåœ¨å¾®è°ƒæ—¶å†»ç»“åŸå‚æ•°ï¼Œä»…æ›´æ–° Adapter å±‚ã€‚\n",
    "\n",
    "å…·ä½“è€Œè¨€ï¼Œå…¶åœ¨é¢„è®­ç»ƒæ¨¡å‹æ¯å±‚ä¸­æ’å…¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å‚æ•°ï¼Œå³ Adapter æ¨¡å—ï¼Œåœ¨å¾®è°ƒæ—¶å†»ç»“æ¨¡å‹ä¸»ä½“ï¼Œä»…è®­ç»ƒç‰¹å®šäºä»»åŠ¡çš„å‚æ•°ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n",
    "\n",
    "<div align='center'>\n",
    "    <img src=\"https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/3-1.png\" alt=\"alt text\" width=\"90%\">\n",
    "    <p>å›¾6.8 Adapt Tuning</p>\n",
    "</div>\n",
    "\n",
    "æ¯ä¸ª Adapter æ¨¡å—ç”±ä¸¤ä¸ªå‰é¦ˆå­å±‚ç»„æˆï¼Œç¬¬ä¸€ä¸ªå‰é¦ˆå­å±‚å°† Transformer å—çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œå°†åŸå§‹è¾“å…¥ç»´åº¦ $d$ æŠ•å½±åˆ° $m$ï¼Œé€šè¿‡æ§åˆ¶ $m$ çš„å¤§å°æ¥é™åˆ¶ Adapter æ¨¡å—çš„å‚æ•°é‡ï¼Œé€šå¸¸æƒ…å†µä¸‹ $m << d$ã€‚åœ¨è¾“å‡ºé˜¶æ®µï¼Œé€šè¿‡ç¬¬äºŒä¸ªå‰é¦ˆå­å±‚è¿˜åŸè¾“å…¥ç»´åº¦ï¼Œå°† $m$ é‡æ–°æŠ•å½±åˆ° $d$ï¼Œä½œä¸º Adapter æ¨¡å—çš„è¾“å‡º(å¦‚ä¸Šå›¾å³ä¾§ç»“æ„)ã€‚\n",
    "\n",
    "LoRA äº‹å®ä¸Šå°±æ˜¯ä¸€ç§æ”¹è¿›çš„ Adapt Tuning æ–¹æ³•ã€‚ä½† Adapt Tuning æ–¹æ³•å­˜åœ¨æ¨ç†å»¶è¿Ÿé—®é¢˜ï¼Œç”±äºå¢åŠ äº†é¢å¤–å‚æ•°å’Œé¢å¤–è®¡ç®—é‡ï¼Œå¯¼è‡´å¾®è°ƒä¹‹åçš„æ¨¡å‹è®¡ç®—é€Ÿåº¦ç›¸è¾ƒåŸé¢„è®­ç»ƒæ¨¡å‹æ›´æ…¢ã€‚\n",
    "\n",
    "**Prefix Tuning**ã€‚è¯¥ç§æ–¹æ³•å›ºå®šé¢„è®­ç»ƒ LMï¼Œä¸º LM æ·»åŠ å¯è®­ç»ƒï¼Œä»»åŠ¡ç‰¹å®šçš„å‰ç¼€ï¼Œè¿™æ ·å°±å¯ä»¥ä¸ºä¸åŒä»»åŠ¡ä¿å­˜ä¸åŒçš„å‰ç¼€ï¼Œå¾®è°ƒæˆæœ¬ä¹Ÿå°ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æ¯ä¸€ä¸ªè¾“å…¥ token å‰æ„é€ ä¸€æ®µä¸ä¸‹æ¸¸ä»»åŠ¡ç›¸å…³çš„ virtual tokens ä½œä¸º prefixï¼Œåœ¨å¾®è°ƒæ—¶åªæ›´æ–° prefix éƒ¨åˆ†çš„å‚æ•°ï¼Œè€Œå…¶ä»–å‚æ•°å†»ç»“ä¸å˜ã€‚\n",
    "\n",
    "ä¹Ÿæ˜¯ç›®å‰å¸¸ç”¨çš„å¾®é‡å¾®è°ƒæ–¹æ³•çš„ Ptuningï¼Œå…¶å®å°±æ˜¯ Prefix Tuning çš„ä¸€ç§æ”¹è¿›ã€‚ä½† Prefix Tuning ä¹Ÿå­˜åœ¨å›ºå®šçš„ç¼ºé™·ï¼šæ¨¡å‹å¯ç”¨åºåˆ—é•¿åº¦å‡å°‘ã€‚ç”±äºåŠ å…¥äº† virtual tokensï¼Œå ç”¨äº†å¯ç”¨åºåˆ—é•¿åº¦ï¼Œå› æ­¤è¶Šé«˜çš„å¾®è°ƒè´¨é‡ï¼Œæ¨¡å‹å¯ç”¨åºåˆ—é•¿åº¦å°±è¶Šä½ã€‚\n",
    "\n",
    "ç›®å‰ï¼Œæœ€ä¸»æµçš„é«˜æ•ˆå¾®è°ƒæ–¹æ³•æ˜¯ LoRA å¾®è°ƒã€‚LoRA å¾®è°ƒçš„åŸºæœ¬å‡è®¾æ˜¯ï¼Œå¦‚æœä¸€ä¸ªå¤§æ¨¡å‹æ˜¯å°†æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´è¿›è¡Œå¤„ç†ï¼Œè¿™é‡Œå‡å®šåœ¨å¤„ç†ä¸€ä¸ªç»†åˆ†çš„å°ä»»åŠ¡æ—¶ï¼Œæ˜¯ä¸éœ€è¦é‚£ä¹ˆå¤æ‚çš„å¤§æ¨¡å‹çš„ï¼Œå¯èƒ½åªéœ€è¦åœ¨æŸä¸ªå­ç©ºé—´èŒƒå›´å†…å°±å¯ä»¥è§£å†³ï¼Œé‚£ä¹ˆä¹Ÿå°±ä¸éœ€è¦å¯¹å…¨é‡å‚æ•°è¿›è¡Œä¼˜åŒ–äº†ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰å½“å¯¹æŸä¸ªå­ç©ºé—´å‚æ•°è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œèƒ½å¤Ÿè¾¾åˆ°å…¨é‡å‚æ•°ä¼˜åŒ–çš„æ€§èƒ½çš„ä¸€å®šæ°´å¹³ï¼ˆå¦‚90%ç²¾åº¦ï¼‰æ—¶ï¼Œé‚£ä¹ˆè¿™ä¸ªå­ç©ºé—´å‚æ•°çŸ©é˜µçš„ç§©å°±å¯ä»¥ç§°ä¸ºå¯¹åº”å½“å‰å¾…è§£å†³é—®é¢˜çš„æœ¬å¾ç§©ï¼ˆintrinsic rankï¼‰ã€‚\n",
    "\n",
    "é¢„è®­ç»ƒæ¨¡å‹æœ¬èº«å°±éšå¼åœ°é™ä½äº†æœ¬å¾ç§©ï¼Œå½“é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒåï¼Œæ¨¡å‹ä¸­æƒé‡çŸ©é˜µå…¶å®å…·æœ‰æ›´ä½çš„æœ¬å¾ç§©ï¼ˆintrinsic rankï¼‰ã€‚åŒæ—¶ï¼Œè¶Šç®€å•çš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¯¹åº”çš„æœ¬å¾ç§©è¶Šä½ã€‚ï¼ˆ[Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning](https://arxiv.org/abs/2012.13255)ï¼‰å› æ­¤ï¼Œæƒé‡æ›´æ–°çš„é‚£éƒ¨åˆ†å‚æ•°çŸ©é˜µå°½ç®¡éšæœºæŠ•å½±åˆ°è¾ƒå°çš„å­ç©ºé—´ï¼Œä»ç„¶å¯ä»¥æœ‰æ•ˆçš„å­¦ä¹ ï¼Œå¯ä»¥ç†è§£ä¸ºé’ˆå¯¹ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡è¿™äº›æƒé‡çŸ©é˜µå°±ä¸è¦æ±‚æ»¡ç§©ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼˜åŒ–å¯†é›†å±‚åœ¨é€‚åº”è¿‡ç¨‹ä¸­å˜åŒ–çš„ç§©åˆ†è§£çŸ©é˜µæ¥é—´æ¥è®­ç»ƒç¥ç»ç½‘ç»œä¸­çš„ä¸€äº›å¯†é›†å±‚ï¼Œä»è€Œå®ç°ä»…ä¼˜åŒ–å¯†é›†å±‚çš„ç§©åˆ†è§£çŸ©é˜µæ¥è¾¾åˆ°å¾®è°ƒæ•ˆæœã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå‡è®¾é¢„è®­ç»ƒå‚æ•°ä¸º $\\theta^D_0$ï¼Œåœ¨ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡ä¸Šå¯†é›†å±‚æƒé‡å‚æ•°çŸ©é˜µå¯¹åº”çš„æœ¬å¾ç§©ä¸º $\\theta^d$ï¼Œå¯¹åº”ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒå‚æ•°ä¸º $\\theta^D$ï¼Œé‚£ä¹ˆæœ‰ï¼š\n",
    "\n",
    "$$\\theta^D = \\theta^D_0 + \\theta^d M$$\n",
    "\n",
    "è¿™ä¸ª $M$ å³ä¸º LoRA ä¼˜åŒ–çš„ç§©åˆ†è§£çŸ©é˜µã€‚\n",
    "\n",
    "æƒ³å¯¹äºå…¶ä»–é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼ŒLoRA å­˜åœ¨ä»¥ä¸‹ä¼˜åŠ¿ï¼š\n",
    "\n",
    "1. å¯ä»¥é’ˆå¯¹ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡æ„å»ºå°å‹ LoRA æ¨¡å—ï¼Œä»è€Œåœ¨å…±äº«é¢„è®­ç»ƒæ¨¡å‹å‚æ•°åŸºç¡€ä¸Šæœ‰æ•ˆåœ°åˆ‡æ¢ä¸‹æ¸¸ä»»åŠ¡ã€‚\n",
    "2. LoRA ä½¿ç”¨è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼ˆAdaptive Optimizerï¼‰ï¼Œä¸éœ€è¦è®¡ç®—æ¢¯åº¦æˆ–ç»´æŠ¤å¤§å¤šæ•°å‚æ•°çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œè®­ç»ƒæ›´æœ‰æ•ˆã€ç¡¬ä»¶é—¨æ§›æ›´ä½ã€‚\n",
    "3. LoRA ä½¿ç”¨ç®€å•çš„çº¿æ€§è®¾è®¡ï¼Œåœ¨éƒ¨ç½²æ—¶å°†å¯è®­ç»ƒçŸ©é˜µä¸å†»ç»“æƒé‡åˆå¹¶ï¼Œä¸å­˜åœ¨æ¨ç†å»¶è¿Ÿã€‚\n",
    "4. LoRA ä¸å…¶ä»–æ–¹æ³•æ­£äº¤ï¼Œå¯ä»¥ç»„åˆã€‚\n",
    "\n",
    "å› æ­¤ï¼ŒLoRA æˆä¸ºç›®å‰é«˜æ•ˆå¾®è°ƒ LLM çš„ä¸»æµæ–¹æ³•ï¼Œå°¤å…¶æ˜¯å¯¹äºèµ„æºå—é™ã€æœ‰ç›‘ç£è®­ç»ƒæ•°æ®å—é™çš„æƒ…å†µä¸‹ï¼ŒLoRA å¾®è°ƒå¾€å¾€ä¼šæˆä¸º LLM å¾®è°ƒçš„é¦–é€‰æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b9b4a",
   "metadata": {},
   "source": [
    "### 1.1.2 å¦‚ä½•è¿›è¡Œ LoRA å¾®è°ƒ\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ peft åº“æ¥é«˜æ•ˆã€ä¾¿æ·åœ°å®ç° LoRA å¾®è°ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a7a74c-9d05-4898-8665-c0247f2df60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "file_path=\"formatted_finetune_data.jsonl\"\n",
    "df = pd.read_json(file_path, lines=True, encoding='utf-8') # æ³¨æ„ä¿®æ”¹\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc6aba2-36a3-42d1-b1f5-a21becd9c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "===system_message_test===<|im_end|>\n",
      "<|im_start|>user\n",
      "===user_message_test===<|im_end|>\n",
      "<|im_start|>assistant\n",
      "===assistant_message_test===<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ¨¡å‹ tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained('model/Qwen/Qwen3-4B-Instruct-2507', trust_remote=True)\n",
    "\n",
    "# æ‰“å°ä¸€ä¸‹ chat template\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"===system_message_test===\"},\n",
    "    {\"role\": \"user\", \"content\": \"===user_message_test===\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"===assistant_message_test===\"},\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb13d6e-04f6-4bb2-87e5-f643bb76fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_multi_turn_qwen(example):\n",
    "\n",
    "    MAX_LENGTH = 1024\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "\n",
    "    # 1. æå–å¯¹è¯å†…å®¹\n",
    "    # å‡è®¾æ¯æ¡æ•°æ®éƒ½æ˜¯ä» system å¼€å§‹ï¼Œç„¶å human/gpt äº¤æ›¿\n",
    "    convs = example['conversations']\n",
    "\n",
    "    # 2. æ„é€ ç¬¦åˆ Qwen3 ChatML æ ¼å¼çš„è¾“å…¥\n",
    "    # Qwen3 ä¾ç„¶éµå¾ª <|im_start|> è¿™ç§ Prompt æ ¼å¼\n",
    "    # instruction_text = \"\"\n",
    "\n",
    "    for msg in convs:\n",
    "        role = msg[\"from\"]\n",
    "        content = msg[\"value\"]\n",
    "\n",
    "        if role == \"human\":\n",
    "            role = \"user\"\n",
    "        elif role == \"gpt\":\n",
    "            role = \"assistant\"\n",
    "        # 1. æ„é€ è§’è‰²å‰ç¼€: <|im_start|>system\\n æˆ– <|im_start|>user\\n ç­‰\n",
    "        prefix = f\"<|im_start|>{role}\\n\"\n",
    "        prefix_ids = tokenizer(prefix, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        # 2. æ„é€ å†…å®¹: {content}\n",
    "        content_ids = tokenizer(content, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        # 3. æ„é€ åç¼€: <|im_end|>\\n\n",
    "        suffix = \"<|im_end|>\\n\"\n",
    "        suffix_ids = tokenizer(suffix, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        # æ‹¼æ¥å½“å‰è½®æ¬¡çš„å®Œæ•´ ID\n",
    "        current_turn_ids = prefix_ids + content_ids + suffix_ids\n",
    "        input_ids.extend(current_turn_ids)\n",
    "\n",
    "        # è®¾ç½® Labels: åªæœ‰è§’è‰²ä¸º assistant æ—¶ï¼Œcontent å’Œ suffix éƒ¨åˆ†æ‰è®¡ç®— Loss\n",
    "        if role == \"assistant\":\n",
    "            # å‰ç¼€éƒ¨åˆ†ä¸å­¦ (-100)\n",
    "            turn_labels = [-100] * len(prefix_ids)\n",
    "            # å†…å®¹å’Œç»“æŸç¬¦è¦å­¦ (content_ids + suffix_ids)\n",
    "            turn_labels += content_ids + suffix_ids\n",
    "            labels.extend(turn_labels)\n",
    "        else:\n",
    "            # system å’Œ user çš„æ‰€æœ‰éƒ¨åˆ†éƒ½ä¸å­¦ (-100)\n",
    "            labels.extend([-100] * len(current_turn_ids))\n",
    "\n",
    "    # ç»Ÿä¸€æˆªæ–­\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17126ea1-fc88-4d96-be77-77d7039a8d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576c64bc4dcb4740b475c993659d1844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è½¦è½½åŠ©æ‰‹ã€‚å½“å‰ç”¨æˆ·ä¿¡æ¯: {\\'Age\\': 80, \\'Technological_Proficiency\\': \\'middle\\'}ã€‚ ç”¨æˆ·çš„é•¿æœŸåå¥½åŒ…æ‹¬: Favorite Cuisine: Italian, Preferred type of Charging when being at everyday points (f.e. work, grocery, restaurant): AC, Charging Station Amenities: Wi-Fi availability, Priority for Shortest Time or Shortest Distance: Shortest Distance, Traffic Information Source Preferences: NavFlow Updates, Preferred Parking Type: On-street, Preference for Parking with Security: Yes, Fan Speed Preferences: High, Favorite Songs: Asphalt Anthems by Gritty Lyricist (Rap), Favorite Podcast Genres: Healthã€‚è¯·åŸºäºè¿™äº›ä¿¡æ¯æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚<|im_end|>\\n<|im_start|>user\\næœ€è¿‘æˆ‘ä¸€ç›´ç‰¹åˆ«æƒ³åƒæ­£å®—çš„æ„å¤§åˆ©èœï¼Œä½ èƒ½æ¨èé™„è¿‘ä¸é”™çš„æ„å¤§åˆ©é¤å…å—ï¼Ÿ<|im_end|>\\n<|im_start|>assistant\\næ²¡é—®é¢˜ï¼Œé™„è¿‘4å…¬é‡Œå¤„æœ‰å®¶è¯„åˆ†å¾ˆé«˜çš„æ„å¤§åˆ©é¤å…La Cucinaã€‚è¦æˆ‘ä¸ºæ‚¨å¯¼èˆªè¿‡å»å—ï¼Ÿ<|im_end|>\\n<|im_start|>user\\n\"La Cucina\"å¬èµ·æ¥å¾ˆä¸é”™ï¼Œè¯·å¼€å¯å¯¼èˆªã€‚<|im_end|>\\n<|im_start|>assistant\\nå¯¼èˆªå‰å¾€La Cucinaé¤å…çš„è·¯çº¿å·²å¯åŠ¨ã€‚é¢„è®¡çº¦12åˆ†é’Ÿååˆ°è¾¾ã€‚ç¥æ‚¨ç”¨é¤æ„‰å¿«ï¼<|im_end|>\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ä¸Šæ–‡å®šä¹‰çš„å‡½æ•°å¯¹æ•°æ®é›†è¿›è¡Œå¤„ç†\n",
    "tokenized_id = ds.map(preprocess_multi_turn_qwen, remove_columns=ds.column_names)\n",
    "tokenized_id\n",
    "tokenizer.decode(tokenized_id[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d304ae2-ab60-4080-a80d-19cac2e3ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=2, target_modules={'up_proj', 'o_proj', 'v_proj', 'gate_proj', 'k_proj', 'q_proj', 'down_proj'}, exclude_modules=None, lora_alpha=8, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é¦–å…ˆé…ç½® LoRA å‚æ•°\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, # ä»»åŠ¡ç±»å‹ä¸º CLMï¼Œå³ SFT ä»»åŠ¡çš„ç±»å‹\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # ç›®æ ‡æ¨¡å—ï¼Œå³éœ€è¦è¿›è¡Œ LoRA å¾®è°ƒçš„æ¨¡å—\n",
    "    inference_mode=False, # è®­ç»ƒæ¨¡å¼\n",
    "    r=2, # Lora ç§©ï¼Œå³ LoRA å¾®è°ƒçš„ç»´åº¦\n",
    "    lora_alpha=8, # Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†\n",
    "    lora_dropout=0.1# Dropout æ¯”ä¾‹\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c2489c5-eaab-4e1f-b06a-c3f914b4bf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c77d5d0ebe4ae1ad6a621bbf7a0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='model/Qwen/Qwen3-4B-Instruct-2507', revision=None, inference_mode=False, r=2, target_modules={'up_proj', 'o_proj', 'v_proj', 'gate_proj', 'k_proj', 'q_proj', 'down_proj'}, exclude_modules=None, lora_alpha=8, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# é‡æ–°åŠ è½½ä¸€ä¸ª Base æ¨¡å‹\n",
    "model = AutoModelForCausalLM.from_pretrained('model/Qwen/Qwen3-4B-Instruct-2507', device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()\n",
    "# é€šè¿‡ä¸‹åˆ—ä»£ç å³å¯å‘æ¨¡å‹ä¸­æ·»åŠ  LoRA æ¨¡å—\n",
    "model = get_peft_model(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf5482b-fab9-4eb3-ad88-c116def4be12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,128,768 || all params: 4,026,596,864 || trainable%: 0.1025\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹ lora å¾®è°ƒçš„æ¨¡å‹å‚æ•°\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73a211a5-3df6-4e25-9e78-44d90a2dc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "\n",
    "# é…ç½®è®­ç»ƒå‚æ•°\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen3_4B_lora\", # è¾“å‡ºç›®å½•\n",
    "    per_device_train_batch_size=8, # æ¯ä¸ªè®¾å¤‡ä¸Šçš„è®­ç»ƒæ‰¹é‡å¤§å°\n",
    "    gradient_accumulation_steps=4, # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "    logging_steps=10, # æ¯10æ­¥æ‰“å°ä¸€æ¬¡æ—¥å¿—\n",
    "    num_train_epochs=2, # è®­ç»ƒè½®æ•°\n",
    "    save_steps=100, # æ¯100æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡å‹\n",
    "    learning_rate=1e-4, # å­¦ä¹ ç‡\n",
    "    save_on_each_node=True, # æ˜¯å¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šä¿å­˜æ¨¡å‹\n",
    "    gradient_checkpointing=True, # æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹\n",
    "    report_to=\"none\", # ä¸ä½¿ç”¨ä»»ä½•æŠ¥å‘Šå·¥å…·\n",
    ")\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen3-4B-lora\", \n",
    "    experiment_name=\"Qwen3-4B-experiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b997b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç„¶ååŒæ ·ä½¿ç”¨ trainer è®­ç»ƒå³å¯\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9faedcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca9fef15cd44e238a5adba06db913b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> swanlab version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> is available!  Upgrade: `pip install -U swanlab`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m swanlab version \u001b[1;36m0.7\u001b[0m.\u001b[1;36m8\u001b[0m is available!  Upgrade: `pip install -U swanlab`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e388a45f654919878b890cbed6864c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Tracking run with swanlab version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Tracking run with swanlab version \u001b[1;36m0.6\u001b[0m.\u001b[1;36m8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Run data will be saved locally in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/root/autodl-tmp/swanlog/run-20260209_001335-oblkj2azancnis3tsa0tp</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Run data will be saved locally in \u001b[1;35m/root/autodl-tmp/swanlog/run-20260209_001335-oblkj2azancnis3tsa0tp\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> </span>ğŸ‘‹ Hi <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">xiaomingchen</span>,welcome to swanlab!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m\u001b[1;34m \u001b[0mğŸ‘‹ Hi \u001b[1;39mxiaomingchen\u001b[0m,welcome to swanlab!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Syncing run <span style=\"color: #808000; text-decoration-color: #808000\">Qwen3-4B-experiment</span> to the cloud\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Syncing run \u001b[33mQwen3-4B-experiment\u001b[0m to the cloud\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸ  View project at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@xiaomingchen/Qwen3-4B-lora</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸ  View project at \u001b[4;34mhttps://swanlab.cn/@xiaomingchen/Qwen3-4B-lora\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> ğŸš€ View run at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@xiaomingchen/Qwen3-4B-lora/runs/oblkj2azancnis3tsa0tp</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m ğŸš€ View run at \u001b[4;34mhttps://swanlab.cn/@xiaomingchen/Qwen3-4B-lora/runs/oblkj2azancnis3tsa0tp\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@xiaomingchen/Qwen3-4B-lora/runs/oblkj2azancnis3tsa0tp\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 06:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.895500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64, training_loss=2.3296501711010933, metrics={'train_runtime': 377.3342, 'train_samples_per_second': 5.3, 'train_steps_per_second': 0.17, 'total_flos': 1.863036602285261e+16, 'train_loss': 2.3296501711010933, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc0c69",
   "metadata": {},
   "source": [
    "LoRA å¾®è°ƒä»…ä¿å­˜å¾®è°ƒåçš„ LoRA å‚æ•°ï¼Œå› æ­¤æ¨ç†å¾®è°ƒæ¨¡å‹éœ€è¦åŠ è½½ LoRA å‚æ•°å¹¶åˆå¹¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2a415a-a9ad-49ea-877f-243558a83bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5015e29213584a6493a515d43dc1387c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "model_path = '/root/autodl-tmp/model/Qwen/Qwen3-4B-Instruct-2507'# åŸºåº§æ¨¡å‹å‚æ•°è·¯å¾„\n",
    "lora_path = './output/Qwen3_4B_lora/checkpoint-64' # è¿™é‡Œæ”¹æˆä½ çš„ lora è¾“å‡ºå¯¹åº” checkpoint åœ°å€\n",
    "\n",
    "# åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, rust_remote_code=True)\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\",torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "\n",
    "# åŠ è½½loraæƒé‡\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dff0799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ— æ³•ç›´æ¥æ’­æ”¾ç”µå°å¹¿æ’­ã€‚ä¸è¿‡æˆ‘å¯ä»¥ä¸ºæ‚¨æ’­æŠ¥æœ€æ–°çš„æ–°é—»æ‘˜è¦ï¼Œæˆ–è€…æä¾›æ‚¨æ„Ÿå…´è¶£çš„æ–°é—»èµ„è®¯ã€‚éœ€è¦æˆ‘ä¸ºæ‚¨ä»‹ç»å½“å‰çš„çƒ­ç‚¹æ–°é—»å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ä½ æ˜¯è°ï¼Ÿ\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "                                    [{\"role\": \"user\", \"content\": \"å¼€å§‹æ’­æ”¾æ–°é—»ç”µå°\"}],\n",
    "                                    add_generation_prompt=True,\n",
    "                                    tokenize=True,\n",
    "                                    return_tensors=\"pt\",\n",
    "                                    return_dict=True,\n",
    "                                    enable_thinking=False\n",
    "                                )\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
