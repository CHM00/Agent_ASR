# filename: agent_brain.py
import os
import json
import asyncio
import requests
from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
from openai import AsyncOpenAI
from duckduckgo_search import DDGS
from dotenv import load_dotenv
from Milvus import MilvusClass

# åŠ è½½ç¯å¢ƒå˜é‡(.envæ–‡ä»¶)
load_dotenv()
# import os
# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7897'
# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7897'


class SmartAgentBrain:
    def __init__(self):
        # ================= é…ç½®åŒºåŸŸ (è¯·ä¿®æ”¹è¿™é‡Œ) =================
        self.ARK_API_KEY = os.environ.get("ARK_API_KEY")  # å¡«å…¥ä½ çš„ API Key
        self.ARK_BASE_URL = os.environ.get("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
        self.LLM_MODEL = "deepseek-ai/DeepSeek-V3"  # ä½ çš„æ¨ç†æ¨¡å‹ ID
        self.EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-4B"  # ä½ çš„ Embedding æ¨¡å‹ ID

        self.MILVUS_URI = os.environ.get("URL")  # Milvus åœ°å€
        self.MILVUS_TOKEN = os.environ.get("Token")  # Milvus Token
        # =======================================================

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.aclient = AsyncOpenAI(
            api_key=self.ARK_API_KEY,
            base_url=self.ARK_BASE_URL,
        )

        # åˆå§‹åŒ–æœç´¢å·¥å…·
        self.ddgs = DDGS(proxy="http://127.0.0.1:7897")


        # self.connect_milvus()

        self.history = []  # [æ–°å¢] çŸ­æœŸå†å²è®°å½•çª—å£
        self.max_history_len = 6  # åªä¿ç•™æœ€è¿‘6è½®å¯¹è¯

        # åˆå§‹åŒ–ç±»
        self.milvus = MilvusClass()
        self.milvus.connect_milvus()
        self.memory_collection = self.milvus.memory_collection
        self.collection = self.milvus.food_collection


    # def connect_milvus(self):
    #     """è¿æ¥ Milvus æ•°æ®åº“å¹¶åˆå§‹åŒ–è®°å¿†é›†åˆ"""
    #     try:
    #         connections.connect(alias="link", uri=self.MILVUS_URI, token=self.MILVUS_TOKEN)
    #         print("âœ… [Brain] Milvus è¿æ¥æˆåŠŸ")
    #
    #         # 1. åŠ è½½åŸæœ‰çš„é£Ÿç‰©æ•°æ®åº“ (ä¿æŒä¸å˜)
    #         self.collection = Collection(name="MilVus_test", using="link")
    #         self.collection.load()
    #
    #         # 2. [æ–°å¢] åˆå§‹åŒ–ç”¨æˆ·è®°å¿†é›†åˆ 'User_Memory'
    #         self.init_memory_collection()
    #
    #     except Exception as e:
    #         print(f"âš ï¸ [Brain] Milvus è¿æ¥å¤±è´¥æˆ–é›†åˆåˆå§‹åŒ–é”™: {e}")
    #         self.collection = None

    # def init_memory_collection(self):
    #     """[æ–°å¢] åˆ›å»ºæˆ–åŠ è½½ç”¨æˆ·è®°å¿†é›†åˆ"""
    #     mem_name = "User_Memory"
    #     if utility.has_collection(mem_name, using="link"):
    #         self.memory_collection = Collection(mem_name, using="link")
    #         self.memory_collection.load()
    #         print(f"ğŸ§  [Memory] åŠ è½½é•¿æœŸè®°å¿†åº“: {mem_name}")
    #     else:
    #         # å®šä¹‰ Schema
    #         fields = [
    #             FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    #             FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=2560),  # ç»´åº¦éœ€ä¸ Embedding æ¨¡å‹ä¸€è‡´
    #             FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000),  # å­˜å‚¨è®°å¿†æ–‡æœ¬
    #             FieldSchema(name="timestamp", dtype=DataType.INT64)  # å¯é€‰ï¼šæ—¶é—´æˆ³
    #         ]
    #         schema = CollectionSchema(fields, "ç”¨æˆ·é•¿æœŸç”»åƒè®°å¿†")
    #         self.memory_collection = Collection(mem_name, schema, using="link")
    #
    #         # åˆ›å»ºç´¢å¼•
    #         index_params = {"metric_type": "IP", "index_type": "FLAT", "params": {"M": 8, "efConstruction": 64}}
    #         self.memory_collection.create_index("vector", index_params)
    #         self.memory_collection.load()
    #         print(f"ğŸ†• [Memory] æ–°å»ºé•¿æœŸè®°å¿†åº“: {mem_name}")
    # ä¿®æ”¹ SenseVoice_Agent_Brain.py ä¸­çš„ SmartAgentBrain ç±»

    async def update_memory_logic(self, new_fact):
        """
        æ ¸å¿ƒè®°å¿†æ›´æ–°é€»è¾‘ï¼šæ£€ç´¢ -> æ¯”è¾ƒ -> (åˆ é™¤æ—§çš„) -> å†™å…¥æ–°çš„
        """
        if not self.memory_collection: return

        print(f"ğŸ¤” [Memory] æ­£åœ¨è¯„ä¼°æ–°è®°å¿†: {new_fact}")

        # 1. å…ˆå»æœä¸€ä¸‹æœ‰æ²¡æœ‰ç›¸å…³çš„æ—§è®°å¿†
        # é˜ˆå€¼è®¾ä½ä¸€ç‚¹(0.4)ï¼Œç¡®ä¿èƒ½æœåˆ°ç›¸å…³çš„ï¼›å¤ªé«˜å¯èƒ½æ¼æ‰çŸ›ç›¾ç‚¹
        similar_memories = self.milvus.search_memory(new_fact, top_k=3)

        # è¿‡æ»¤æ‰ç›¸ä¼¼åº¦å¤ªä½çš„ï¼Œåªä¿ç•™çœŸæ­£ç›¸å…³çš„
        candidates = [m for m in similar_memories if m['score'] > 0.4]

        ids_to_delete = []

        # 2. å¦‚æœæ‰¾åˆ°äº†ç›¸ä¼¼è®°å¿†ï¼Œéœ€è¦ LLM ä»‹å…¥åˆ¤æ–­å†²çª
        if candidates:
            candidates_str = "\n".join([f"ID:{m['id']} å†…å®¹:{m['text']}" for m in candidates])

            check_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªè®°å¿†ç®¡ç†å‘˜ã€‚è¯·åˆ¤æ–­ã€æ–°ä¿¡æ¯ã€‘ä¸ã€å·²æœ‰è®°å¿†ã€‘çš„å…³ç³»ã€‚

            ã€å·²æœ‰è®°å¿†ã€‘:
            {candidates_str}

            ã€æ–°ä¿¡æ¯ã€‘:
            {new_fact}

            é€»è¾‘åˆ¤æ–­è§„åˆ™: 
            1. **å†²çª/ä¿®æ­£**: å¦‚æœæ–°ä¿¡æ¯ä¸æ—§è®°å¿†çŸ›ç›¾ï¼ˆå¦‚â€œå–œæ¬¢è¾£â€å˜â€œä¸åƒè¾£â€ï¼‰ï¼Œæˆ–è€…æ–°ä¿¡æ¯æ˜¯æ—§è®°å¿†çš„æ›´æ–°ç‰ˆæœ¬ï¼Œè¾“å‡º "DELETE: <æ—§è®°å¿†ID>"ã€‚
            2. **å†—ä½™**: å¦‚æœæ–°ä¿¡æ¯åœ¨å·²æœ‰è®°å¿†ä¸­å®Œå…¨åŒ…å«äº†ï¼Œä¸éœ€è¦é‡å¤è®°å½•ï¼Œè¾“å‡º "IGNORE"ã€‚
            3. **è¡¥å……/æ— å…³**: å¦‚æœæ–°ä¿¡æ¯æ˜¯è¡¥å……çš„æ–°çŸ¥è¯†ï¼Œä¸æ—§è®°å¿†ä¸å†²çªï¼Œè¾“å‡º "KEEP"ã€‚

            è¯·åªè¾“å‡ºå†³ç­–ç»“æœã€‚å¦‚æœæœ‰å¤šä¸ªIDè¦åˆ é™¤ï¼Œç”¨é€—å·åˆ†éš”ã€‚
            ç¤ºä¾‹è¾“å‡º: "DELETE: 44213, 44215" æˆ– "IGNORE" æˆ– "KEEP"
            """

            try:
                check_res = await self.aclient.chat.completions.create(
                    model=self.LLM_MODEL,
                    messages=[{"role": "user", "content": check_prompt}],
                    temperature=0.0
                )
                decision = check_res.choices[0].message.content.strip()
                print(f"âš–ï¸ [Memory] è®°å¿†å†²çªè£å†³: {decision}")

                if "IGNORE" in decision:
                    print("ğŸš« [Memory] ä¿¡æ¯å†—ä½™ï¼Œè·³è¿‡å†™å…¥ã€‚")
                    return  # ç›´æ¥ç»“æŸï¼Œä¸å†™å…¥

                if "DELETE:" in decision:
                    # è§£æè¦åˆ é™¤çš„ ID
                    id_str = decision.split("DELETE:")[1].strip()
                    # å¤„ç†å¯èƒ½å‡ºç°çš„éæ•°å­—å­—ç¬¦
                    import re
                    ids = re.findall(r'\d+', id_str)
                    ids_to_delete = [int(i) for i in ids]

            except Exception as e:
                print(f"âŒ [Memory] è£å†³è¿‡ç¨‹å‡ºé”™: {e}")

        # 3. æ‰§è¡Œæ“ä½œ
        # å¦‚æœæœ‰è¦åˆ é™¤çš„æ—§è®°å¿†ï¼Œå…ˆåˆ é™¤
        if ids_to_delete:
            self.milvus.delete_memory_by_ids(ids_to_delete)

        # å†™å…¥æ–°è®°å¿† (ä½¿ç”¨åŸæ¥çš„ insert é€»è¾‘ï¼Œä½†è¦ç¡®ä¿è°ƒç”¨çš„æ˜¯ milvus å®ä¾‹çš„æ–¹æ³•)
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ Milvus ç±»é‡Œçš„ insert é€»è¾‘ï¼Œæˆ–è€…ä½ åœ¨è¿™é‡Œæ‰‹åŠ¨ insert
        vec = self.milvus.embedding(new_fact)
        if vec:
            import time
            data = [[vec], [new_fact], [int(time.time())]]
            self.memory_collection.insert(data)
            # self.memory_collection.flush() # é¢‘ç¹ flush å½±å“æ€§èƒ½ï¼Œå¯ä»¥ç´¯ç§¯æˆ–å®šæ—¶ flush
            print(f"ğŸ’¾ [Memory] å†™å…¥æ–°è®°å¿†: {new_fact}")

    async def extract_and_save_memory(self, user_text):
        """[åå°ä»»åŠ¡] æå–äº‹å®å¹¶è§¦å‘æ›´æ–°æµç¨‹"""
        prompt = f"""
        åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæå–ç”¨æˆ·çš„æ ¸å¿ƒç”»åƒäº‹å®ï¼ˆå–œå¥½ã€ä¹ æƒ¯ã€èº«ä½“çŠ¶å†µã€è®¡åˆ’ï¼‰ã€‚
        åªæå–**é•¿æœŸæœ‰æ•ˆ**çš„ä¿¡æ¯ã€‚
        å¦‚æœæ— æœ‰æ•ˆä¿¡æ¯ï¼Œè¾“å‡º "NONE"ã€‚

        ç”¨æˆ·è¾“å…¥: "{user_text}"
        è¾“å‡ºç¤ºä¾‹: "ç”¨æˆ·ç°åœ¨ä¸åƒè¾£äº†"
        """
        try:
            res = await self.aclient.chat.completions.create(
                model=self.LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            fact = res.choices[0].message.content.strip()

            if fact and "NONE" not in fact and len(fact) > 2:
                # æ”¹ä¸ºè°ƒç”¨æ–°çš„æ›´æ–°é€»è¾‘
                await self.update_memory_logic(fact)

        except Exception as e:
            print(f"è®°å¿†æå–é”™è¯¯: {e}")

    # def remember_fact(self, text):
    #     """å†™å…¥è®°å¿†ï¼šå°†æ–‡æœ¬å‘é‡åŒ–å¹¶å­˜å…¥ Milvus"""
    #     if not self.memory_collection: return
    #
    #     vec = self.milvus.embedding(text)
    #     if vec:
    #         import time
    #         # æ’å…¥æ•°æ®
    #         data = [
    #             [vec],  # vector
    #             [text],  # text
    #             [int(time.time())]  # timestamp
    #         ]
    #         self.memory_collection.insert(data)
    #         self.memory_collection.flush()  # å¼ºåˆ¶è½ç›˜
    #         print(f"ğŸ’¾ [Memory] å·²è®°ä½: {text}")

    def recall_memories(self, query, top_k=2):
        """å›å¿†ï¼šæ ¹æ®å½“å‰è¯é¢˜æ£€ç´¢ç›¸å…³è®°å¿†"""
        if not self.memory_collection: return []

        vec = self.milvus.embedding(query)
        if not vec: return []

        search_params = {"metric_type": "IP", "params": {"ef": 64}}
        try:
            res = self.memory_collection.search(
                data=[vec], anns_field="vector", param=search_params, limit=top_k,
                output_fields=["text"]
            )
            # æå–æ–‡æœ¬
            memories = [hit.entity.get("text") for hit in res[0] if hit.distance > 0.4]  # é˜ˆå€¼è¿‡æ»¤ï¼Œé¿å…ä¸ç›¸å…³çš„è®°å¿†
            if memories:
                print(f"ğŸ’­ [Memory] æƒ³èµ·äº†: {memories}")
            return memories
        except Exception as e:
            print(f"âŒ [Memory] å›å¿†å¤±è´¥: {e}")
            return []

    # async def extract_and_save_memory(self, user_text):
    #     """[åå°ä»»åŠ¡] ä½¿ç”¨ LLM åˆ¤æ–­ç”¨æˆ·è¯´çš„è¯æ˜¯å¦åŒ…å«å€¼å¾—è®°å½•çš„äº‹å®"""
    #     # å¹¶ä¸æ˜¯æ¯ä¸€å¥è¯éƒ½è¦è®°ï¼Œåªæœ‰åŒ…å«â€œæˆ‘...â€çš„äº‹å®æ‰å€¼å¾—è®°
    #     prompt = f"""
    #     åˆ†æç”¨æˆ·çš„è¯ï¼Œæå–å…³äºç”¨æˆ·çš„æ ¸å¿ƒäº‹å®ï¼ˆå¦‚å–œå¥½ã€å…³ç³»ã€ä½ç½®ã€è®¡åˆ’ç­‰ï¼‰ã€‚
    #     å¦‚æœåŒ…å«æœ‰ä»·å€¼çš„é•¿æœŸä¿¡æ¯ï¼Œè¯·æå–ä¸ºç®€çŸ­çš„é™ˆè¿°å¥ã€‚
    #     å¦‚æœæ²¡æœ‰ï¼ˆå¦‚ä»…ä»…æ˜¯é—®å€™æˆ–é—²èŠï¼‰ï¼Œè¾“å‡º "NONE"ã€‚
    #
    #     ç”¨æˆ·è¾“å…¥: "{user_text}"
    #
    #     è¾“å‡ºç¤ºä¾‹:
    #     ç”¨æˆ·: "æˆ‘ä¸ä»…ä»…å–œæ¬¢åƒè‹¹æœï¼Œè¿˜å¯¹èŠ±ç”Ÿè¿‡æ•" -> "ç”¨æˆ·å–œæ¬¢åƒè‹¹æœï¼Œä¸”å¯¹èŠ±ç”Ÿè¿‡æ•"
    #     ç”¨æˆ·: "ä»Šå¤©å¤©æ°”ä¸é”™" -> "NONE"
    #     """
    #     try:
    #         res = await self.aclient.chat.completions.create(
    #             model=self.LLM_MODEL,
    #             messages=[{"role": "user", "content": prompt}],
    #             temperature=0.1
    #         )
    #         fact = res.choices[0].message.content.strip()
    #         if fact and "NONE" not in fact and len(fact) > 2:
    #             self.remember_fact(fact)
    #     except Exception as e:
    #         print(f"è®°å¿†æå–é”™è¯¯: {e}")



    # def connect_milvus(self):
    #     """è¿æ¥ Milvus æ•°æ®åº“"""
    #     try:
    #         # è°ƒè¯•ï¼šæ‰“å°è¿æ¥å‚æ•°
    #         print(f"ğŸ”§ [Debug] MILVUS_URI: {self.MILVUS_URI}")
    #         print(f"ğŸ”§ [Debug] MILVUS_TOKEN: {'å·²è®¾ç½®' if self.MILVUS_TOKEN else 'æœªè®¾ç½®'}")
    #
    #         connections.connect(alias="link", uri=self.MILVUS_URI, token=self.MILVUS_TOKEN)
    #         print("âœ… [Brain] Milvus è¿æ¥æˆåŠŸ")
    #         # å‡è®¾é›†åˆå·²ç»å­˜åœ¨ (ç”±ä¹‹å‰çš„è„šæœ¬åˆ›å»º)
    #         self.collection = Collection(name="MilVus_test", using="link")
    #         self.collection.load()
    #     except Exception as e:
    #         print(f"âš ï¸ [Brain] Milvus è¿æ¥å¤±è´¥æˆ–é›†åˆä¸å­˜åœ¨: {e}")
    #         self.collection = None

    # def get_embedding(self, text):
    #     """è°ƒç”¨ Embedding API"""
    #     # api_key = "610764dc-5ee9-41b1-aac8-1c9728a1e5cf"
    #     # url = "https://ark.cn-beijing.volces.com/api/v3/embeddings"
    #     url = self.ARK_BASE_URL + '/embeddings'
    #     # url = "https://ark.cn-beijing.volces.com/api/v3/embeddings"
    #     headers = {
    #         "Content-Type": "application/json",
    #         "Authorization": f"Bearer {self.ARK_API_KEY}"
    #     }
    #     data = {
    #         "input": [text],
    #         "model": self.EMBEDDING_MODEL,
    #         "embedding_dimension": 2560  # ç¡®ä¿è·Ÿä½ çš„æ¨¡å‹ä¸€è‡´
    #     }
    #     try:
    #         print("æ‰§è¡Œå“åº”Embeddingè¯·æ±‚:")
    #         response = requests.post(url, headers=headers, json=data)
    #         result = response.json()
    #         return result['data'][0]["embedding"]
    #     except Exception as e:
    #         print(f"âŒ [Brain] Embedding å¤±è´¥: {e}")
    #         return None

    def search_food_db(self, query_text):
        """æŸ¥è¯¢ Milvus æ•°æ®åº“"""
        if not self.collection:
            print("âŒ [Brain] Milvus é›†åˆä¸å¯ç”¨ï¼Œæ— æ³•æŸ¥è¯¢æ•°æ®åº“")
            return None

        print(f"ğŸ” [Brain] æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“: {query_text}")
        vec = self.milvus.embedding(query_text)
        if not vec: return None

        search_params = {"metric_type": "IP", "params": {"ef": 128}}
        try:
            res = self.collection.search(
                data=[vec],
                anns_field="vector",
                param=search_params,
                limit=5,
                output_fields=["item_name"]
            )
            print("æ£€ç´¢ç»“æœåˆ†æ: ", res)
            if res and res[0]:
                return res[0][0].entity.get('item_name')
        except Exception as e:
            print(f"âŒ [Brain] æ£€ç´¢å‡ºé”™: {e}")
        return None

    def search_web(self, query, max_results=2):
        """è”ç½‘æœç´¢ï¼ˆå¸¦é‡è¯•ï¼‰"""
        print(f"ğŸŒ [Brain] æ­£åœ¨è”ç½‘æœç´¢: {query} ...")
        for attempt in range(3):
            try:
                results = list(self.ddgs.text(query, max_results=max_results))
                print("result:", results)
                if not results:
                    return ""
                return "\n".join([f"æ ‡é¢˜: {r['title']}\næ‘˜è¦: {r['body']}" for r in results])
            except Exception as e:
                print(f"âš ï¸ [Brain] æœç´¢å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < 2:
                    import time
                    time.sleep(1)
        return ""

    # def search_web(self, query, max_results=2):
    #     """è”ç½‘æœç´¢"""
    #     print(f"ğŸŒ [Brain] æ­£åœ¨è”ç½‘æœç´¢: {query} ...")
    #     try:
    #         results = list(self.ddgs.text(query, max_results=max_results))
    #         if not results: return ""
    #         return "\n".join([f"æ ‡é¢˜: {r['title']}\næ‘˜è¦: {r['body']}" for r in results])
    #     except Exception as e:
    #         print(f"âŒ [Brain] æœç´¢å¤±è´¥: {e}")
    #         return ""

    async def process_user_query(self, user_text):
        """
        æ ¸å¿ƒå¤„ç†æµï¼šæ„å›¾è¯†åˆ« -> (æŸ¥åº“ OR è”ç½‘ OR é—²èŠ) -> ç”Ÿæˆå›å¤
        """

        # --- 1. å›å¿† (Long-Term Retrieval) ---
        related_memories = self.recall_memories(user_text)
        memory_str = ""
        if related_memories:
            memory_str = f"ã€å·²çŸ¥ç”¨æˆ·ä¿¡æ¯ã€‘: {';'.join(related_memories)}"
            print(f"ğŸ§  æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡: {memory_str}")

        # 1. æ„å›¾è·¯ç”± Prompt
        route_prompt = f"""
        è¯·åˆ†æç”¨æˆ·æ–‡æœ¬ï¼Œè¿”å› JSON æ ¼å¼ï¼ˆä¸è¦Markdownï¼‰ï¼š
        1. Call_elm (bool): æ˜¯å¦æƒ³ç‚¹å¤–å–/è¯¢é—®èœå“ï¼Ÿ
        2. Food_candidate (str): å…·ä½“èœåæˆ–å£å‘³éœ€æ±‚ï¼Œæ— åˆ™ä¸ºç©ºã€‚
        3. Need_Search (str): å¦‚éœ€æŸ¥è¯¢å®æ—¶ä¿¡æ¯(æ–°é—»/å¤©æ°”/ç™¾ç§‘)è¯·è¾“å‡ºæœç´¢å…³é”®è¯ï¼Œå¦åˆ™ä¸ºç©ºã€‚

        ç”¨æˆ·è¾“å…¥ï¼š"{user_text}"

        ç¤ºä¾‹ï¼š{{"Call_elm": true, "Food_candidate": "çš®è›‹ç²¥", "Need_Search": ""}}
        ç¤ºä¾‹ï¼š{{"Call_elm": false, "Food_candidate": "", "Need_Search": "åŒ—äº¬å¤©æ°”"}}
        """

        try:
            # --- ç¬¬ä¸€æ­¥ï¼šè·¯ç”±å†³ç­– ---
            route_res = await self.aclient.chat.completions.create(
                model=self.LLM_MODEL,
                messages=[{"role": "user", "content": route_prompt}],
                temperature=0.1
            )
            raw_json = route_res.choices[0].message.content.replace("```json", "").replace("```", "").strip()
            intent = json.loads(raw_json)
            print(f"ğŸ§  [Brain] æ„å›¾åˆ†æ: {intent}")

            final_response = ""

            # --- åˆ†æ”¯ A: ç‚¹é¤ä¸šåŠ¡ ---
            if intent.get("Call_elm"):
                food_name = intent.get("Food_candidate")
                matched = self.search_food_db(food_name)
                if matched:
                    final_response = f"æ‰¾åˆ°å•¦ï¼æˆ‘ä»¬è¦ä¸è¦æ¥ä¸€ä»½{matched}ï¼Ÿ"
                else:
                    final_response = f"æŠ±æ­‰ï¼Œèœå•é‡Œå¥½åƒæ²¡æœ‰æ‰¾åˆ°{food_name}ï¼Œæ¢ä¸ªåˆ«çš„è¯•è¯•ï¼Ÿ"

            # --- åˆ†æ”¯ B: è”ç½‘æœç´¢ ---
            elif intent.get("Need_Search"):
                search_q = intent.get("Need_Search")
                search_ctx = self.search_web(search_q)
                print("æœç´¢ç»“æœ: ", search_ctx)

                # è”ç½‘å›ç­”ä¹Ÿéœ€è¦å¸¦ä¸Šå†å²è®°å¿†ï¼ˆæ¯”å¦‚â€œåŒ—äº¬å¤©æ°”â€ï¼Œè®°å¿†ä¸­æœ‰â€œç”¨æˆ·æ€•å†·â€ï¼‰
                gen_prompt = f"""
                                {memory_str}
                                åŸºäºæœç´¢ç»“æœå’Œç”¨æˆ·è®°å¿†å›ç­”ã€‚
                                ç”¨æˆ·é—®é¢˜ï¼š{user_text}
                                æœç´¢ç»“æœï¼š{search_ctx}
                                """
                resp = await self.aclient.chat.completions.create(
                    model=self.LLM_MODEL,
                    messages=[{"role": "user", "content": gen_prompt}]
                )
                final_response = resp.choices[0].message.content

                # gen_prompt = f"åŸºäºæœç´¢ç»“æœå›ç­”ç”¨æˆ·ï¼š{user_text}\n\næœç´¢ç»“æœï¼š\n{search_ctx}"
                # resp = await self.aclient.chat.completions.create(
                #     model=self.LLM_MODEL,
                #     messages=[{"role": "user", "content": gen_prompt}]
                # )
                # final_response = resp.choices[0].message.content

            # --- åˆ†æ”¯ C: çº¯é—²èŠ ---
            else:
                system_msg = "ä½ å«å°åƒï¼Œæ˜¯ä¸€ä¸ªæ´»æ³¼å¯çˆ±çš„è¯­éŸ³åŠ©æ‰‹ï¼Œå›ç­”è¯·ç®€çŸ­ã€‚"
                if memory_str:
                    system_msg += f"\n{memory_str}\nè¯·åœ¨èŠå¤©ä¸­è‡ªç„¶è¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œä½“ç°ä½ è®°å¾—ç”¨æˆ·ã€‚"

                messages = [{"role": "system", "content": system_msg}]
                messages.extend(self.history)  # åŠ å…¥çŸ­æœŸå†å²
                messages.append({"role": "user", "content": user_text})

                chat_res = await self.aclient.chat.completions.create(
                    model=self.LLM_MODEL,
                    messages=messages
                )
                final_response = chat_res.choices[0].message.content


                # chat_res = await self.aclient.chat.completions.create(
                #     model=self.LLM_MODEL,
                #     messages=[
                #         {"role": "system", "content": "ä½ å«å°åƒï¼Œæ˜¯ä¸€ä¸ªæ´»æ³¼å¯çˆ±çš„è¯­éŸ³åŠ©æ‰‹ï¼Œå›ç­”è¯·ç®€çŸ­(50å­—ä»¥å†…)ã€‚"},
                #         {"role": "user", "content": user_text}
                #     ]
                # )
                # final_response = chat_res.choices[0].message.content
            # --- æ”¶å°¾å·¥ä½œ ---
            # 1. æ›´æ–°çŸ­æœŸè®°å¿†
            self.history.append({"role": "user", "content": user_text})
            self.history.append({"role": "assistant", "content": final_response})
            if len(self.history) > self.max_history_len:
                self.history = self.history[-self.max_history_len:]

            # 2. [å¼‚æ­¥] æå–å¹¶ä¿å­˜æ–°è®°å¿†
            # ä½¿ç”¨ asyncio.create_task è®©å®ƒåœ¨åå°è¿è¡Œï¼Œä¸é˜»å¡å½“å‰çš„è¯­éŸ³æ’­æŠ¥
            asyncio.create_task(self.extract_and_save_memory(user_text))

            return final_response

        except Exception as e:
            print(f"âŒ [Brain] å¤„ç†å¼‚å¸¸: {e}")
            return "ä¸å¥½æ„æ€ï¼Œæˆ‘çš„å¤§è„‘åˆšåˆšçŸ­è·¯äº†ä¸€ä¸‹ï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    brain = SmartAgentBrain()
    print(asyncio.run(brain.process_user_query("æˆ‘æƒ³åƒä¸‰é²œä¹Œå†¬é¢")))
    print(asyncio.run(brain.process_user_query("ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·")))