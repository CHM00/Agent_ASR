# filename: agent_brain.py
import os
import json
import asyncio
import requests
from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
from openai import AsyncOpenAI
from duckduckgo_search import DDGS
from dotenv import load_dotenv
from Milvus import MilvusClass
from tavily import TavilyClient
from Local_Model import Load_Model
import threading
# åŠ è½½ç¯å¢ƒå˜é‡(.envæ–‡ä»¶)
load_dotenv()
# import os
# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7897'
# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7897'


class SmartAgentBrain:
    def __init__(self, LOCAL_LLM=False):
        # ================= é…ç½®åŒºåŸŸ (è¯·ä¿®æ”¹è¿™é‡Œ) =================
        self.ARK_API_KEY = os.environ.get("ARK_API_KEY")  # å¡«å…¥ä½ çš„ API Key
        self.ARK_BASE_URL = os.environ.get("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
        self.LLM_MODEL = "deepseek-ai/DeepSeek-V3"  # ä½ çš„æ¨ç†æ¨¡å‹ ID
        self.EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-4B"  # ä½ çš„ Embedding æ¨¡å‹ ID

        self.MILVUS_URI = os.environ.get("URL")  # Milvus åœ°å€
        self.MILVUS_TOKEN = os.environ.get("Token")  # Milvus Token

        self.search_web_key = os.environ.get("trivily_key")
        # =======================================================

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.aclient = AsyncOpenAI(
            api_key=self.ARK_API_KEY,
            base_url=self.ARK_BASE_URL,
        )

        # æ£€ç´¢å·¥å…·
        self.client = TavilyClient(self.search_web_key)
        # self.connect_milvus()

        self.history = []  # çŸ­æœŸå†å²è®°å½•çª—å£
        self.max_history_len = 6  # åªä¿ç•™æœ€è¿‘6è½®å¯¹è¯

        # åˆå§‹åŒ–ç±»
        self.milvus = MilvusClass()
        self.milvus.connect_milvus()
        self.memory_collection = self.milvus.memory_collection
        self.collection = self.milvus.food_collection

        # åˆå§‹åŒ–æœ¬åœ°ç±»
        self.local_model  = Load_Model()
        self.LOCAL_LLM = LOCAL_LLM

    async def update_memory_logic(self, new_fact, user_id):
        """
        æ ¸å¿ƒè®°å¿†æ›´æ–°é€»è¾‘ï¼šæ£€ç´¢ -> æ¯”è¾ƒ -> (åˆ é™¤æ—§çš„) -> å†™å…¥æ–°çš„
        """
        if not self.memory_collection: return

        print(f"[Memory] æ­£åœ¨è¯„ä¼°æ–°è®°å¿†: {new_fact}")

        # 1. å…ˆå»æœä¸€ä¸‹æœ‰æ²¡æœ‰ç›¸å…³ä¸ªäººçš„æ—§è®°å¿†
        similar_memories = self.milvus.search_memory(new_fact, user_id=user_id, top_k=3)
        # similar_memories = self.milvus.search_memory(new_fact, top_k=3)

        # è¿‡æ»¤æ‰ç›¸ä¼¼åº¦å¤ªä½çš„ï¼Œåªä¿ç•™çœŸæ­£ç›¸å…³çš„
        candidates = [m for m in similar_memories if m['score'] > 0.4]

        ids_to_delete = []

        # 2. å¦‚æœæ‰¾åˆ°äº†ç›¸ä¼¼è®°å¿†ï¼Œéœ€è¦ LLM ä»‹å…¥åˆ¤æ–­å†²çª
        if candidates:
            candidates_str = "\n".join([f"ID:{m['id']} å†…å®¹:{m['text']}" for m in candidates])

            check_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªè®°å¿†ç®¡ç†å‘˜ã€‚è¯·åˆ¤æ–­ã€æ–°ä¿¡æ¯ã€‘ä¸ã€å·²æœ‰è®°å¿†ã€‘çš„å…³ç³»ã€‚

            ã€å·²æœ‰è®°å¿†ã€‘:
            {candidates_str}

            ã€æ–°ä¿¡æ¯ã€‘:
            {new_fact}

            é€»è¾‘åˆ¤æ–­è§„åˆ™: 
            1. **å†²çª/ä¿®æ­£**: å¦‚æœæ–°ä¿¡æ¯ä¸æ—§è®°å¿†çŸ›ç›¾ï¼ˆå¦‚â€œå–œæ¬¢è¾£â€å˜â€œä¸åƒè¾£â€ï¼‰ï¼Œæˆ–è€…æ–°ä¿¡æ¯æ˜¯æ—§è®°å¿†çš„æ›´æ–°ç‰ˆæœ¬ï¼Œè¾“å‡º "DELETE: <æ—§è®°å¿†ID>"ã€‚
            2. **å†—ä½™**: å¦‚æœæ–°ä¿¡æ¯åœ¨å·²æœ‰è®°å¿†ä¸­å®Œå…¨åŒ…å«äº†ï¼Œä¸éœ€è¦é‡å¤è®°å½•ï¼Œè¾“å‡º "IGNORE"ã€‚
            3. **è¡¥å……/æ— å…³**: å¦‚æœæ–°ä¿¡æ¯æ˜¯è¡¥å……çš„æ–°çŸ¥è¯†ï¼Œä¸æ—§è®°å¿†ä¸å†²çªï¼Œè¾“å‡º "KEEP"ã€‚

            è¯·åªè¾“å‡ºå†³ç­–ç»“æœã€‚å¦‚æœæœ‰å¤šä¸ªIDè¦åˆ é™¤ï¼Œç”¨é€—å·åˆ†éš”ã€‚
            ç¤ºä¾‹è¾“å‡º: "DELETE: 44213, 44215" æˆ– "IGNORE" æˆ– "KEEP"
            """

            try:
                messages = [{"role": "user", "content": check_prompt}]
                if self.LOCAL_LLM:
                    # åŸºäºæœ¬åœ°éƒ¨ç½²çš„LLM
                    check_res = self.local_model.llm_chat(messages)
                    decision = check_res.strip()
                else:
                    # åŸºäºAPIå®ç°
                    check_res = await self.aclient.chat.completions.create(
                        model=self.LLM_MODEL,
                        messages=messages,
                        temperature=0.0
                    )
                    decision = check_res.choices[0].message.content.strip()
                print(f"[Memory] è®°å¿†å†²çªè£å†³: {decision}")

                if "IGNORE" in decision:
                    print("[Memory] ä¿¡æ¯å†—ä½™ï¼Œè·³è¿‡å†™å…¥ã€‚")
                    return  # ç›´æ¥ç»“æŸï¼Œä¸å†™å…¥

                if "DELETE:" in decision:
                    # è§£æè¦åˆ é™¤çš„ ID
                    id_str = decision.split("DELETE:")[1].strip()
                    # å¤„ç†å¯èƒ½å‡ºç°çš„éæ•°å­—å­—ç¬¦
                    import re
                    ids = re.findall(r'\d+', id_str)
                    ids_to_delete = [int(i) for i in ids]

            except Exception as e:
                print(f"[Memory] è£å†³è¿‡ç¨‹å‡ºé”™: {e}")

        # 3. æ‰§è¡Œæ“ä½œ
        # å¦‚æœæœ‰è¦åˆ é™¤çš„æ—§è®°å¿†ï¼Œå…ˆåˆ é™¤
        if ids_to_delete:
            print(f"[Memory] å‡†å¤‡åˆ é™¤å†²çªè®°å¿†: {ids_to_delete} (æ‰€å±ç”¨æˆ·: {user_id})")
            self.milvus.delete_memory_by_ids(ids_to_delete, user_id)

        # å†™å…¥æ–°è®°å¿† (ä½¿ç”¨åŸæ¥çš„ insert é€»è¾‘ï¼Œä½†è¦ç¡®ä¿è°ƒç”¨çš„æ˜¯ milvus å®ä¾‹çš„æ–¹æ³•)
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ Milvus ç±»é‡Œçš„ insert é€»è¾‘ï¼Œæˆ–è€…ä½ åœ¨è¿™é‡Œæ‰‹åŠ¨ insert
        vec = self.milvus.embedding(new_fact)
        if vec:
            import time

            self.milvus.insert_memory(new_fact, user_id)

            print(f"[Memory] å†™å…¥æ–°è®°å¿†: {new_fact}, å…³äºç”¨æˆ· {user_id}")

    async def extract_and_save_memory(self, user_text, user_id):
        """[åå°ä»»åŠ¡] æå–äº‹å®å¹¶è§¦å‘æ›´æ–°æµç¨‹"""
        print(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: {user_text}")
        prompt = f"""
        ### ä»»åŠ¡ï¼šæå–ç”¨æˆ·é•¿æœŸæœ‰æ•ˆæ ¸å¿ƒç”»åƒä¿¡æ¯
        1.  **æå–èŒƒå›´ï¼ˆä»…ä»¥ä¸‹4ç±»é•¿æœŸä¿¡æ¯ï¼‰**
            - å–œå¥½ï¼šé•¿æœŸç¨³å®šçš„å…´è¶£ã€é¥®é£Ÿåå¥½ã€çˆ±å¥½ï¼ˆä¾‹ï¼šå–œæ¬¢åƒç”œé£Ÿã€é•¿æœŸå–œæ¬¢æ‰“ç¯®çƒï¼‰
            - ä¹ æƒ¯ï¼šé•¿æœŸä¿æŒçš„è¡Œä¸ºæ¨¡å¼ï¼ˆä¾‹ï¼šæ¯å¤©æ—©ä¸Šè·‘æ­¥ã€ä¹ æƒ¯æ—©ç¡æ—©èµ·ï¼‰
            - èº«ä½“çŠ¶å†µï¼šé•¿æœŸç¨³å®šçš„å¥åº·çŠ¶æ€ï¼ˆä¾‹ï¼šå¯¹ç‰›å¥¶è¿‡æ•ã€æœ‰æ…¢æ€§å’½ç‚ï¼‰
            - è®¡åˆ’ï¼šé•¿æœŸè§„åˆ’æˆ–å›ºå®šå®‰æ’ï¼ˆä¾‹ï¼šæ‰“ç®—ä»Šå¹´è€ƒé©¾ç…§ã€è®¡åˆ’æ¯æœˆè¯»ä¸¤æœ¬ä¹¦ï¼‰
        2.  **æ’é™¤æ¡ä»¶ï¼ˆè¿™äº›ä¿¡æ¯ä¸æå–ï¼‰**
            - çŸ­æœŸä¸´æ—¶éœ€æ±‚ï¼šæ¯”å¦‚"ä»Šå¤©æƒ³åƒç«é”…"ã€"æ˜å¤©è¦å»é€›è¡—"
            - ä¸€æ¬¡æ€§è¡Œä¸ºï¼šæ¯”å¦‚"æ˜¨å¤©çœ‹äº†ç”µå½±"ã€"ä¸Šå‘¨ä¹°äº†è¡£æœ"
            - æ— æ˜ç¡®é•¿æœŸå±æ€§çš„å†…å®¹ï¼šæ¯”å¦‚"è¿™ä¸ªç”µå½±å¾ˆå¥½çœ‹"ã€"ä»Šå¤©å¤©æ°”ä¸é”™"
        3.  **è¾“å‡ºè§„åˆ™**
            - ä»…æå–ç”¨æˆ·æ˜ç¡®è¡¨è¿°çš„**é•¿æœŸæœ‰æ•ˆ**ä¿¡æ¯ï¼Œä¸åšä»»ä½•æ¨æµ‹ã€æ‰©å±•ã€æ€»ç»“
            - ä¿¡æ¯å¿…é¡»ç›´æ¥æ¥è‡ªç”¨æˆ·è¾“å…¥ï¼Œä¸èƒ½æ·»åŠ é¢å¤–è¯æ±‡
            - æ ¼å¼ï¼šç”¨é™ˆè¿°å¥ç›´æ¥æè¿°ï¼Œè¯­è¨€ç®€æ´
            - å¦‚æœæ²¡æœ‰ç¬¦åˆè¦æ±‚çš„é•¿æœŸä¿¡æ¯ï¼Œ**ä¸¥æ ¼è¾“å‡ºå¤§å†™çš„ NONE**ï¼Œä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•å†…å®¹
        4.  **ç¤ºä¾‹å‚è€ƒ**
            ç¤ºä¾‹1ï¼š
            ç”¨æˆ·è¾“å…¥: "æˆ‘å¯¹æµ·é²œè¿‡æ•ï¼Œä¸€ç›´éƒ½ä¸èƒ½åƒ"
            è¾“å‡º: ç”¨æˆ·å¯¹æµ·é²œè¿‡æ•
            ç¤ºä¾‹2ï¼š
            ç”¨æˆ·è¾“å…¥: "æˆ‘æ¯å¤©éƒ½è¦å–ä¸€æ¯å’–å•¡ï¼Œè¿™æ˜¯å¤šå¹´çš„ä¹ æƒ¯"
            è¾“å‡º: ç”¨æˆ·æ¯å¤©å–ä¸€æ¯å’–å•¡
            ç¤ºä¾‹3ï¼š
            ç”¨æˆ·è¾“å…¥: "æˆ‘ä»Šå¤©æƒ³åƒéº»è¾£çƒ«"
            è¾“å‡º: NONE
            ç¤ºä¾‹4ï¼š
            ç”¨æˆ·è¾“å…¥: "æˆ‘æ‰“ç®—æ˜å¹´å»å›½å¤–ç•™å­¦ï¼Œå·²ç»è§„åˆ’å¾ˆä¹…äº†"
            è¾“å‡º: ç”¨æˆ·æ‰“ç®—æ˜å¹´å»å›½å¤–ç•™å­¦
            ç¤ºä¾‹5ï¼š
            ç”¨æˆ·è¾“å…¥: "æ˜¨å¤©æˆ‘å»è·‘æ­¥äº†"
            è¾“å‡º: NONE

        ### ç”¨æˆ·è¾“å…¥
        "{user_text}"

        ### æœ€ç»ˆè¾“å‡º
        """
        try:

            messages = [{"role": "user", "content": prompt}]
            if self.LOCAL_LLM:
                # åŸºäºæœ¬åœ°LLM
                print("æœ¬åœ°LLM")
                res = self.local_model.llm_chat(messages)
                print("æå–è®°å¿†ç»“æœ: ", res)
                fact = res.strip()
            else:
                # åŸºäºAPI
                print("åŸºäºAPI")
                res = await asyncio.wait_for(
                    self.aclient.chat.completions.create(
                        model=self.LLM_MODEL,
                        messages=messages,
                        temperature=0.1
                    ),
                    timeout=30.0  # 30ç§’è¶…æ—¶
                )
                # res = await self.aclient.chat.completions.create(
                #     model=self.LLM_MODEL,
                #     messages=messages,
                #     temperature=0.1
                # )
                fact = res.choices[0].message.content.strip()
            print("fact: ", fact)
            if fact and "NONE" not in fact:
                await self.update_memory_logic(fact, user_id)
        except Exception as e:
            print(f"è®°å¿†æå–é”™è¯¯: {e}")

    def recall_memories(self, query, user_id, top_k=2):
        # ä¼ é€’ user_id ç»™ milvus
        results = self.milvus.search_memory(query, user_id=user_id, top_k=top_k)
        memories = [item["text"] for item in results]
        return memories


    def search_food_db(self, query_text):
        """æŸ¥è¯¢ Milvus æ•°æ®åº“"""
        if not self.collection:
            print("[Brain] Milvus é›†åˆä¸å¯ç”¨ï¼Œæ— æ³•æŸ¥è¯¢æ•°æ®åº“")
            return None

        print(f"[Brain] æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“: {query_text}")
        vec = self.milvus.embedding(query_text)
        if not vec: return None

        search_params = {"metric_type": "IP", "params": {"ef": 128}}
        try:
            res = self.collection.search(
                data=[vec],
                anns_field="vector",
                param=search_params,
                limit=5,
                output_fields=["item_name"]
            )
            print("æ£€ç´¢ç»“æœåˆ†æ: ", res)
            if res and res[0]:
                return res[0][0].entity.get('item_name')
        except Exception as e:
            print(f"[Brain] æ£€ç´¢å‡ºé”™: {e}")
        return None

    def search_web(self, query, max_results=2):
        """è”ç½‘æœç´¢ï¼ˆå¸¦é‡è¯•ï¼‰"""
        print(f"[Brain] æ­£åœ¨è”ç½‘æœç´¢: {query} ...")
        for attempt in range(3):
            try:
                response = self.client.search(
                    query=query,
                    search_depth="advanced"
                )
                results = response["results"][:max_results]
                print("result:", results)
                if not results:
                    return ""
                return "\n".join([f"æ ‡é¢˜: {r['title']}\næ‘˜è¦: {r['content']}" for r in results])
            except Exception as e:
                print(f"[Brain] æœç´¢å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < 2:
                    import time
                    time.sleep(1)
        return ""


    async def process_user_query(self, user_text, user_id):
        """
            æ„å›¾è¯†åˆ« -> (æŸ¥åº“ OR è”ç½‘ OR é—²èŠ) -> ç”Ÿæˆå›å¤
        """
        print(f"ğŸ§  [Brain] å¤„ç†è¯·æ±‚ï¼Œå½“å‰ç”¨æˆ·: {user_id}")

        # --- å›å¿†ç‰¹å®šç”¨æˆ·è®°å¿†æˆåˆ† ---
        related_memories = self.recall_memories(user_text, user_id)
        memory_str = ""
        if related_memories:
            memory_str = f"ã€å…³äº {user_id} çš„è®°å¿†ã€‘: {';'.join(related_memories)}"

        # æ„å›¾è·¯ç”± Prompt, é’ˆå¯¹å°æ¨¡å‹çš„ä¼˜åŒ– Prompt, å¢å¼ºå…¶æŒ‡ä»¤éµå¾ªçš„èƒ½åŠ›
        route_prompt = f"""
        ### è§’è‰²è®¾å®š
        ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«APIã€‚ä»…è¾“å‡ºJSONæ ¼å¼ç»“æœï¼Œä¸è¦åŒ…å«Markdownæ ‡è®°æˆ–å…¶ä»–æ–‡å­—ã€‚

        ### å­—æ®µå®šä¹‰
        - Call_elm (bool): æ˜¯å¦åŒ…å«ç‚¹é¤/å¤–å–æ„å›¾(æƒ³åƒã€ç‚¹èœç­‰)ã€‚
        - Food_candidate (str): æå–å…·ä½“çš„èœå/é£Ÿç‰©ã€‚
        - Need_Search (str): æå–éœ€è¦è”ç½‘æœç´¢çš„å…³é”®è¯(å¤©æ°”/ç™¾ç§‘/ä»·æ ¼ç­‰)ã€‚
        - Register_Action (str): æå–æ³¨å†Œæ„å›¾ã€‚è‹¥åŒ…å«åå­—æå–åå­—(å¦‚"æˆ‘æ˜¯å¼ ä¸‰"); è‹¥æƒ³æ³¨å†Œä½†æœªæä¾›åå­—è¾“å‡º"Unknown_User"; å¦åˆ™ä¸ºç©ºã€‚

        ### å‚è€ƒç¤ºä¾‹ (è¯·ä¸¥æ ¼æ¨¡ä»¿ä»¥ä¸‹æ ¼å¼)
        è¾“å…¥: "æˆ‘æƒ³åƒçš®è›‹ç˜¦è‚‰ç²¥"
        JSON: {{"Call_elm": true, "Food_candidate": "çš®è›‹ç˜¦è‚‰ç²¥", "Need_Search": "", "Register_Action": ""}}

        è¾“å…¥: "æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”"
        JSON: {{"Call_elm": false, "Food_candidate": "", "Need_Search": "æ˜å¤©åŒ—äº¬å¤©æ°”", "Register_Action": ""}}

        è¾“å…¥: "æˆ‘è¦æ³¨å†Œæ–°ç”¨æˆ·"
        JSON: {{"Call_elm": false, "Food_candidate": "", "Need_Search": "", "Register_Action": "Unknown_User"}}

        è¾“å…¥: "æˆ‘æ˜¯å¼ ä¸‰ï¼ŒæŠŠæˆ‘çš„å£°éŸ³å½•è¿›å»"
        JSON: {{"Call_elm": false, "Food_candidate": "", "Need_Search": "", "Register_Action": "å¼ ä¸‰"}}

        è¾“å…¥: "éšä¾¿èŠèŠ"
        JSON: {{"Call_elm": false, "Food_candidate": "", "Need_Search": "", "Register_Action": ""}}

        ### å½“å‰ä»»åŠ¡
        è¾“å…¥: "{user_text}"
        JSON: """

        try:
            # --- ç¬¬ä¸€æ­¥ï¼šè·¯ç”±å†³ç­– ---
            messages = [{"role": "user", "content": route_prompt}]
            if self.LOCAL_LLM:
                # æœ¬åœ°éƒ¨ç½²llm
                print("æœ¬åœ°éƒ¨ç½²è°ƒç”¨")
                route_res = self.local_model.llm_chat(messages)
                print("route_res:", route_res)
                raw_json = route_res.replace("```json", "").replace("```", "").strip()
            else:
                # APIæ¥å£
                print("æ‰§è¡Œapiè°ƒç”¨")
                route_res = await self.aclient.chat.completions.create(
                    model=self.LLM_MODEL,
                    messages=messages,
                    temperature=0.1
                )
                raw_json = route_res.choices[0].message.content.replace("```json", "").replace("```", "").strip()
            print("raw_json:", raw_json)
            intent = json.loads(raw_json)
            print(f"[Brain] æ„å›¾åˆ†æ: {intent}")

            final_response = ""

            # --- åˆ†æ”¯ A: ç‚¹é¤ä¸šåŠ¡ ---
            if intent.get("Call_elm"):
                food_name = intent.get("Food_candidate")
                matched = self.search_food_db(food_name)
                if matched:
                    final_response = f"æ‰¾åˆ°å•¦ï¼æˆ‘ä»¬è¦ä¸è¦æ¥ä¸€ä»½{matched}ï¼Ÿ"
                else:
                    final_response = f"æŠ±æ­‰ï¼Œèœå•é‡Œå¥½åƒæ²¡æœ‰æ‰¾åˆ°{food_name}ï¼Œæ¢ä¸ªåˆ«çš„è¯•è¯•ï¼Ÿ"

            # --- åˆ†æ”¯ B: è”ç½‘æœç´¢ ---
            elif intent.get("Need_Search"):
                search_q = intent.get("Need_Search")
                search_ctx = self.search_web(search_q)
                print("æœç´¢ç»“æœ: ", search_ctx)

                # è”ç½‘å›ç­”ä¹Ÿéœ€è¦å¸¦ä¸Šå†å²è®°å¿†ï¼ˆæ¯”å¦‚â€œåŒ—äº¬å¤©æ°”â€ï¼Œè®°å¿†ä¸­æœ‰â€œç”¨æˆ·æ€•å†·â€ï¼‰
                gen_prompt = f"""
                ### ä»»åŠ¡è¦æ±‚
                ä½ éœ€è¦ç»“åˆã€ç”¨æˆ·è®°å¿†ã€‘å’Œã€æœç´¢ç»“æœã€‘ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ»¡è¶³ä»¥ä¸‹ç¡¬æ€§è§„åˆ™ï¼š
                1.  **æè‡´ç®€çŸ­**ï¼šå›ç­”æ§åˆ¶åœ¨2å¥è¯ä»¥å†…ï¼Œæ€»å­—æ•°ä¸è¶…è¿‡30å­—ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œå»æ‰æ‰€æœ‰ä¿®é¥°è¯
                2.  **å£è¯­åŒ–**ï¼šç”¨æ—¥å¸¸è¯´è¯çš„è¯­æ°”ï¼Œé€‚åˆè¯­éŸ³æ’­æŠ¥ï¼Œé¿å…ä¹¦é¢è¯­ã€ä¸“ä¸šæœ¯è¯­
                3.  **ä¼˜å…ˆçº§**ï¼šä¼˜å…ˆä½¿ç”¨ã€æœç´¢ç»“æœã€‘çš„ä¿¡æ¯ï¼›æœç´¢ç»“æœæ— ç›¸å…³å†…å®¹æ—¶ï¼Œå†ç”¨ã€ç”¨æˆ·è®°å¿†ã€‘ï¼›ä¸¤è€…éƒ½æ— åˆ™å›å¤"æš‚æ— ç›¸å…³ä¿¡æ¯"
                4.  **ç¦æ­¢å†…å®¹**ï¼šä¸è§£é‡Šã€ä¸è¡¥å……ã€ä¸æ‰©å±•ï¼Œä¸å‡ºç°æ‹¬å·ã€å¼•å·ç­‰ç‰¹æ®Šç¬¦å·

                ### ã€ç”¨æˆ·è®°å¿†ã€‘
                ä½ æ­£åœ¨å’Œ {user_id} å¯¹è¯ã€‚
                {memory_str}

                ### ã€æœç´¢ç»“æœã€‘
                {search_ctx}

                ### ç”¨æˆ·é—®é¢˜
                {user_text}

                ### ç¤ºä¾‹å‚è€ƒ
                ç¤ºä¾‹1ï¼š
                ç”¨æˆ·è®°å¿†ï¼šç”¨æˆ·å–œæ¬¢å–æ‹¿é“
                æœç´¢ç»“æœï¼šä»Šå¤©å’–å•¡åº—æ‹¿é“ä¹°ä¸€é€ä¸€
                ç”¨æˆ·é—®é¢˜ï¼šä»Šå¤©å–å’–å•¡æœ‰ä¼˜æƒ å—
                è¾“å‡ºï¼šä»Šå¤©å’–å•¡åº—æ‹¿é“ä¹°ä¸€é€ä¸€

                ç¤ºä¾‹2ï¼š
                ç”¨æˆ·è®°å¿†ï¼šç”¨æˆ·å¯¹èŠ’æœè¿‡æ•
                æœç´¢ç»“æœï¼šï¼ˆç©ºï¼‰
                ç”¨æˆ·é—®é¢˜ï¼šæˆ‘èƒ½åƒèŠ’æœå—
                è¾“å‡ºï¼šä½ å¯¹èŠ’æœè¿‡æ•ï¼Œä¸èƒ½åƒ

                ç¤ºä¾‹3ï¼š
                ç”¨æˆ·è®°å¿†ï¼šï¼ˆç©ºï¼‰
                æœç´¢ç»“æœï¼šï¼ˆç©ºï¼‰
                ç”¨æˆ·é—®é¢˜ï¼šæ˜å¤©ä¼šä¸‹é›¨å—
                è¾“å‡ºï¼šæš‚æ— ç›¸å…³ä¿¡æ¯

                ### æœ€ç»ˆè¾“å‡º
                ï¼ˆä»…è¾“å‡ºå›ç­”å†…å®¹ï¼Œæ— å…¶ä»–æ–‡å­—ï¼‰
                """
                messages = [{"role": "user", "content": gen_prompt}]
                if self.LOCAL_LLM:
                    # æœ¬åœ°éƒ¨ç½²llmæ–¹å¼
                    resp = self.local_model.llm_chat(messages)
                    print("resp:", resp)
                    final_response = resp
                else:
                    # åŸºäºAPIçš„è°ƒç”¨æ–¹å¼
                    resp = await self.aclient.chat.completions.create(
                        model=self.LLM_MODEL,
                        messages=messages
                    )
                    final_response = resp.choices[0].message.content

            # --- åˆ†æ”¯ C: æ³¨å†Œå£°çº¹ ---
            elif intent.get("Register_Action"):
                target_name = intent.get("Register_Action")
                # è¿”å›ç‰¹æ®Šæ ‡è®°ç»™ Main å‡½æ•°å¤„ç†
                return f"ACTION_REGISTER:{target_name}"
            else:
                system_msg = f"ä½ å«å°åƒï¼Œæ˜¯ä¸€ä¸ªæ´»æ³¼å¯çˆ±çš„è¯­éŸ³åŠ©æ‰‹ï¼Œç°åœ¨çš„å¯¹è¯è€…æ˜¯ {user_id},å›ç­”è¯·ç®€çŸ­ã€‚"
                if memory_str:
                    system_msg += f"\n{memory_str}\nè¯·åœ¨èŠå¤©ä¸­è‡ªç„¶è¿ç”¨è¿™äº›ä¿¡æ¯ï¼Œä½“ç°ä½ è®°å¾—ç”¨æˆ·ã€‚"

                messages = [{"role": "system", "content": system_msg}]
                messages.extend(self.history)  # åŠ å…¥çŸ­æœŸå†å²
                messages.append({"role": "user", "content": user_text})

                if self.LOCAL_LLM:
                    # åŸºäºæœ¬åœ°LLMå®ç°
                    chat_res = self.local_model.llm_chat(messages)
                    final_response = chat_res
                else:
                    # åŸºäºAPIæ¥å£
                    chat_res = await self.aclient.chat.completions.create(
                        model=self.LLM_MODEL,
                        messages=messages
                    )
                    final_response = chat_res.choices[0].message.content

            # æ›´æ–°çŸ­æœŸè®°å¿†
            self.history.append({"role": "user", "content": user_text})
            self.history.append({"role": "assistant", "content": final_response})
            if len(self.history) > self.max_history_len:
                self.history = self.history[-self.max_history_len:]
            print("æ‰§è¡Œå¼‚æ­¥æ“ä½œ...")
            # æå–å¹¶ä¿å­˜æ–°è®°å¿†, ä½¿ç”¨asyncio.create_taskä¼šé€ æˆå†²çª, æœ€åçš„ä»»åŠ¡æ‰§è¡Œè¢«è·³è¿‡
            # æ˜¯å› ä¸ºasyncio.run(process_user_query()) åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ã€ä¸´æ—¶çš„äº‹ä»¶å¾ªç¯, å½“returnä¹‹å, ä¸»å‡½æ•°æ‰§è¡Œå®Œæ¯•, ç„¶åå°±ä¼šå¼ºåˆ¶ç»ˆæ­¢æ—¶é—´å¾ªç¯


            # å®šä¹‰ä¸€ä¸ªåŒæ­¥çš„åŒ…è£…å‡½æ•°ï¼Œå› ä¸º threading target éœ€è¦åŒæ­¥å‡½æ•°, å®ç°å¹¶è¡Œæ“ä½œ
            def run_memory_task_sync(text, uid):
                # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯æ¥è¿è¡Œè¯¥å¼‚æ­¥ä»»åŠ¡
                try:
                    asyncio.run(self.extract_and_save_memory(text, uid))
                except Exception as e:
                    print(f"åå°è®°å¿†ä»»åŠ¡å‡ºé”™: {e}")

            # å¯åŠ¨å®ˆæŠ¤çº¿ç¨‹ (Daemon Thread)
            # daemon=True æ„å‘³ç€å¦‚æœä¸»ç¨‹åºé€€å‡ºäº†ï¼Œè¿™ä¸ªçº¿ç¨‹ä¹Ÿä¼šéšä¹‹é€€å‡ºï¼Œä¸ä¼šå¡æ­»è¿›ç¨‹
            t = threading.Thread(target=run_memory_task_sync, args=(user_text, user_id), daemon=True)
            t.start()

            return final_response

        except Exception as e:
            print(f"å¤„ç†å¼‚å¸¸: {e}")
            return "ä¸å¥½æ„æ€ï¼Œæˆ‘çš„å¤§è„‘åˆšåˆšçŸ­è·¯äº†ä¸€ä¸‹ï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    brain = SmartAgentBrain()
    # brain.local_model.llm_chat(messages = [{"role": "user", "content": "æ˜å¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}])
    asyncio.run(brain.extract_and_save_memory("æ˜å¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "ä¸»äºº"))
    # brain.extract_and_save_memory("æ˜å¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
    # print("result: ", res)
    # print(asyncio.run(brain.process_user_query("æˆ‘æƒ³åƒä¸‰é²œä¹Œå†¬é¢")))
    # print(asyncio.run(brain.process_user_query("æ˜å¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·")))