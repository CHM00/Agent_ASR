import os
import asyncio
import time
import json, random
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Union

# è¯­éŸ³è¯†åˆ«ç›¸å…³åº“
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

# LLM APIç›¸å…³åº“
from openai import AsyncOpenAI
from dotenv import load_dotenv
# import tqdm
# ä¸MilVuså‘é‡åº“æœ‰å…³
import pandas as pd
from langchain_core.documents import Document
from pymilvus import CollectionSchema, FieldSchema, DataType, Collection, connections, utility
import configparser
import requests

from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

import threading


# åŠ è½½ç¯å¢ƒå˜é‡(.envæ–‡ä»¶)
load_dotenv()

class MilvusClass:
    def __init__(self):
        self.MILVUS_URI = os.environ.get("URL")  # Milvus åœ°å€
        self.MILVUS_TOKEN = os.environ.get("Token")  # Milvus Token
        self.ARK_API_KEY = os.environ.get("ARK_API_KEY")  # å¡«å…¥ä½ çš„ API Key
        self.ARK_BASE_URL = os.environ.get("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
        self.embedding_url = self.ARK_BASE_URL + "/embeddings"
        self.LLM_MODEL = "deepseek-ai/DeepSeek-V3"  # ä½ çš„æ¨ç†æ¨¡å‹ ID
        self.EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-4B"  # ä½ çš„ Embedding æ¨¡å‹ ID
        self.conn = "link"
        self.embedding_dim = 2560
        self.food_name = "Food_List"
        self.mem_name = "User_Memory"
        self.food_collection = None
        self.memory_collection = None

    def connect_milvus(self):
        """è¿æ¥ Milvus æ•°æ®åº“å¹¶åˆå§‹åŒ–è®°å¿†é›†åˆ"""
        try:
            connections.connect(alias="link", uri=self.MILVUS_URI, token=self.MILVUS_TOKEN)
            print("âœ… [Brain] Milvus è¿æ¥æˆåŠŸ")

            # 1. åˆå§‹åŒ–é£Ÿç‰©é›†åˆ 'MilVus_test'
            # self.collection = Collection(name="MilVus_test", using="link")
            # self.collection.load()
            self.init_food_collection()

            # 2. åˆå§‹åŒ–ç”¨æˆ·è®°å¿†é›†åˆ 'User_Memory'
            self.init_memory_collection()

        except Exception as e:
            print(f"âš ï¸ [Brain] Milvus è¿æ¥å¤±è´¥æˆ–é›†åˆåˆå§‹åŒ–é”™: {e}")
            self.food_collection = None
            self.memory_collection = None

    def init_food_collection(self):
        try:
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if utility.has_collection(self.food_name, using=self.conn):
                print(f"é›†åˆ {self.food_name} å­˜åœ¨ã€‚")
                self.food_collection = Collection(name=self.food_name, using=self.conn)
                self.food_collection.load()
                print(f"é›†åˆå­—æ®µ: {[field.name for field in self.food_collection.schema.fields]}")
            else:
                print(f"é›†åˆ {self.food_name} ä¸å­˜åœ¨ï¼Œå‡†å¤‡åˆ›å»ºæ–°é›†åˆã€‚")
                fields = [
                    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=self.embedding_dim),
                    FieldSchema(name="item_name", dtype=DataType.VARCHAR, max_length=255),
                    FieldSchema(name="category_name", dtype=DataType.VARCHAR, max_length=255),
                    FieldSchema(name="cate_1_name", dtype=DataType.VARCHAR, max_length=255),
                    FieldSchema(name="cate_2_name", dtype=DataType.VARCHAR, max_length=255),
                    FieldSchema(name="cate_3_name", dtype=DataType.VARCHAR, max_length=255)
                ]

                # åˆ›å»º Schema
                schema = CollectionSchema(
                    fields=fields,
                    description="data Base Vectors",
                    enable_dynamic_field=False
                )

                # åˆ›å»ºé›†åˆ
                self.food_collection = Collection(name=self.food_name, schema=schema, using=self.conn)
                print(f"é›†åˆ {self.food_name} åˆ›å»ºæˆåŠŸã€‚")

                # åˆ›å»ºç´¢å¼•
                index_params = {
                    "metric_type": "IP",
                    "index_type": "FLAT",
                    "params": {"M": 16, "efConstruction": 200}
                }
                self.food_collection.create_index(field_name="vector", index_params=index_params)
                print("ç´¢å¼•åˆ›å»ºå®Œæˆã€‚")

                # åŠ è½½é›†åˆåˆ°å†…å­˜
                self.food_collection.load()
                print(f"[Food] æ–°å»ºé£Ÿæåº“: {self.food_name}")

        except Exception as e:
            print(f"Milvus æ“ä½œå¤±è´¥: {e}")

    def init_memory_collection(self):
        """åˆ›å»ºæˆ–åŠ è½½ç”¨æˆ·è®°å¿†é›†åˆ"""
        if utility.has_collection(self.mem_name, using="link"):
            self.memory_collection = Collection(self.mem_name, using="link")
            self.memory_collection.load()
            print(f"ğŸ§  [Memory] åŠ è½½é•¿æœŸè®°å¿†åº“: {self.mem_name}")
        else:
            # å®šä¹‰ Schema
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=self.embedding_dim),  # ç»´åº¦éœ€ä¸ Embedding æ¨¡å‹ä¸€è‡´
                FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000),  # å­˜å‚¨è®°å¿†æ–‡æœ¬
                FieldSchema(name="timestamp", dtype=DataType.INT64)  # å¯é€‰ï¼šæ—¶é—´æˆ³
            ]
            schema = CollectionSchema(fields, "ç”¨æˆ·é•¿æœŸç”»åƒè®°å¿†")
            self.memory_collection = Collection(self.mem_name, schema, using="link")

            # åˆ›å»ºç´¢å¼•
            index_params = {"metric_type": "IP", "index_type": "FLAT", "params": {"M": 8, "efConstruction": 64}}
            self.memory_collection.create_index("vector", index_params)
            self.memory_collection.load()
            print(f"ğŸ†• [Memory] æ–°å»ºé•¿æœŸè®°å¿†åº“: {self.mem_name}")


    def embedding(self, text):
        payload = {
            "model": self.EMBEDDING_MODEL,
            "input": f"{text}",
        }
        headers = {
            "Authorization": f"Bearer {self.ARK_API_KEY}",
            "Content-Type": "application/json"
        }

        try:
            response = requests.post(self.embedding_url, json=payload, headers=headers)
            # response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            result = response.json()
            embedding_vec = result['data'][0]["embedding"]
            print(len(embedding_vec))
            # print(result)
            return embedding_vec
        except requests.exceptions.HTTPError as http_err:
            print(f"HTTP é”™è¯¯å‘ç”Ÿ: {http_err}")
        except Exception as err:
            print(f"å…¶ä»–é”™è¯¯å‘ç”Ÿ: {err}")

    def deleteMilvus(self, collection_name="MilVus_test"):
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        try:
            if utility.has_collection(collection_name, using=self.conn):
                print(f"é›†åˆ {collection_name} å­˜åœ¨ã€‚")
                collection = Collection(name=collection_name, using=self.conn)
                print(f"é›†åˆå­—æ®µ: {[field.name for field in collection.schema.fields]}")
                collection.drop()
                print(f"Milvus åˆ é™¤é›†åˆ{collection_name} æˆåŠŸ")
        except Exception as e:
            print(f"Milvus åˆ é™¤é›†åˆå¤±è´¥: {e}")


    def batch_embedding(self, texts: List[str], batch_size: int = 50, max_workers: int = 4) -> List[List[float]]:
        """å¤šçº¿ç¨‹æ‰¹è·å– embedding"""
        all_embeddings = [None] * len(texts)  # é¢„åˆ†é…ï¼Œä¿æŒé¡ºåº
        lock = threading.Lock()

        # åˆ†å‰²æˆæ‰¹æ¬¡
        batches = [(i, texts[i:i + batch_size]) for i in range(0, len(texts), batch_size)]

        def process_batch(batch_info):
            start_idx, batch_texts = batch_info
            payload = {
                "model": self.EMBEDDING_MODEL,
                "input": batch_texts,
            }
            headers = {
                "Authorization": f"Bearer {self.ARK_API_KEY}",
                "Content-Type": "application/json"
            }

            try:
                response = requests.post(self.embedding_url, json=payload, headers=headers)
                response.raise_for_status()
                result = response.json()
                batch_embeddings = [item["embedding"] for item in sorted(result['data'], key=lambda x: x['index'])]
                return start_idx, batch_embeddings
            except Exception as e:
                print(f"æ‰¹é‡ embedding å¤±è´¥ (idx={start_idx}): {e}")
                return start_idx, [[0.0] * self.embedding_dim] * len(batch_texts)

        # å¤šçº¿ç¨‹å¹¶å‘æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_batch, batch): batch for batch in batches}

            for future in tqdm(as_completed(futures), total=len(batches), desc="Embedding å¹¶å‘å¤„ç†"):
                start_idx, embeddings = future.result()
                # æŒ‰åŸå§‹ä½ç½®å­˜å…¥ç»“æœ
                for j, emb in enumerate(embeddings):
                    all_embeddings[start_idx + j] = emb

        return all_embeddings

    # def batch_embedding(self, texts: List[str], batch_size: int = 20) -> List[List[float]]:
    #     """æ‰¹é‡è·å– embeddingï¼Œæ”¯æŒä¸€æ¬¡è¯·æ±‚å¤šæ¡æ–‡æœ¬"""
    #     all_embeddings = []
    #
    #     for i in tqdm(range(0, len(texts), batch_size), desc="Embedding æ‰¹å¤„ç†"):
    #         batch_texts = texts[i:i + batch_size]
    #         payload = {
    #             "model": self.EMBEDDING_MODEL,
    #             "input": batch_texts,  # æ‰¹é‡è¾“å…¥
    #         }
    #         headers = {
    #             "Authorization": f"Bearer {self.ARK_API_KEY}",
    #             "Content-Type": "application/json"
    #         }
    #
    #         try:
    #             response = requests.post(self.embedding_url, json=payload, headers=headers)
    #             response.raise_for_status()
    #             result = response.json()
    #             # æŒ‰é¡ºåºæå– embedding
    #             batch_embeddings = [item["embedding"] for item in sorted(result['data'], key=lambda x: x['index'])]
    #             all_embeddings.extend(batch_embeddings)
    #         except Exception as e:
    #             print(f"æ‰¹é‡ embedding å¤±è´¥: {e}")
    #             # å¤±è´¥æ—¶å¡«å……ç©ºå‘é‡
    #             all_embeddings.extend([[0.0] * self.embedding_dim] * len(batch_texts))
    #
    #     return all_embeddings


    def Batch_insert_food(self, file_path, one_bulk=100, embedding_batch=100):
        # collection_name = "MilVus_test"
        # connections.connect(conn, host=host, port=port)
        # connection = Collection(name=collection_name, using=conn)
        # collection_name = "MilVus_test"
        # connections.connect(alias=self.conn, uri=self.MILVUS_URI, token=self.MILVUS_TOKEN)
        df = pd.read_csv(file_path, sep='\s+')

        # æ’å…¥æ•°æ®
        data_to_insert = []
        valid_rows = []
        texts = []
        for index, row in df.iterrows():
            item_name = str(row['item_name'])
            category_name = str(row['category_name'])
            cate_1_name = str(row['cate_1_name'])
            cate_2_name = str(row['cate_2_name'])
            cate_3_name = str(row['cate_3_name'])

            non_empty_strings = [s for s in [item_name, category_name, cate_1_name, cate_2_name, cate_3_name] if s]
            text = ''.join(non_empty_strings)
            # æ‹¼æ¥æ–‡æœ¬ä¿¡æ¯
            # text = item_name + category_name + cate_1_name + cate_2_name + cate_3_name
            if text:
                texts.append(text)
                valid_rows.append({
                    'item_name': item_name,
                    'category_name': category_name,
                    'cate_1_name': cate_1_name,
                    'cate_2_name': cate_2_name,
                    'cate_3_name': cate_3_name
                })
        # 2. æ‰¹é‡è·å– embedding
        print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡ Embedding ({len(texts)} æ¡æ•°æ®)...")
        # embeddings = self.batch_embedding(texts, batch_size=embedding_batch)
        embeddings = self.batch_embedding(texts, batch_size=100, max_workers=6)

        # 3. ç»„è£…æ•°æ®å¹¶æ‰¹é‡æ’å…¥
        print("\nğŸ“¤ æ’å…¥ Milvus...")
        data_to_insert = []
        for i, (emb, row_data) in enumerate(zip(embeddings, valid_rows)):
            data_to_insert.append([
                emb,
                row_data['item_name'],
                row_data['category_name'],
                row_data['cate_1_name'],
                row_data['cate_2_name'],
                row_data['cate_3_name']
            ])

        # æ‰¹é‡æ’å…¥
        for i in tqdm(range(0, len(data_to_insert), one_bulk), desc="Milvus æ’å…¥"):
            batch_entities = list(map(list, zip(*data_to_insert[i:i + one_bulk])))
            try:
                self.food_collection.insert(batch_entities)
            except Exception as e:
                print(f"æ–‡æ¡£æ’å…¥ Milvus å¤±è´¥: {e}")

        self.food_collection.flush()
        print(f"âœ… å®Œæˆ! å…±æ’å…¥ {len(data_to_insert)} æ¡æ•°æ®")


        # for i in range(0, len(data_to_insert), one_bulk):
        #     batch_entities = list(map(list, zip(*data_to_insert[i:i + one_bulk])))
        #     try:
        #         mr = self.food_collection.insert(batch_entities)
        #     except Exception as e:
        #         print(f"æ–‡æ¡£æ’å…¥ Milvus å¤±è´¥: {e}")
        # self.food_collection.flush()

    # 1. ä¿®æ”¹ search æ–¹æ³•ï¼Œè®©å®ƒè¿”å› IDï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½åˆ é™¤å®ƒ
    def search_memory(self, query_text, top_k=3):
        """ä¸“é—¨ç”¨äºæ£€ç´¢è®°å¿†ï¼Œè¿”å› (id, text, distance)"""
        if not self.memory_collection: return []

        vec = self.embedding(query_text)
        if not vec: return []

        search_params = {"metric_type": "IP", "params": {"ef": 64}}
        try:
            res = self.memory_collection.search(
                data=[vec],
                anns_field="vector",
                param=search_params,
                limit=top_k,
                output_fields=["text", "id"]  # å¿…é¡»è¿”å› ID
            )

            results = []
            for hit in res[0]:
                results.append({
                    "id": hit.id,
                    "text": hit.entity.get("text"),
                    "score": hit.distance
                })
            return results
        except Exception as e:
            print(f"âŒ Milvus æ£€ç´¢å¤±è´¥: {e}")
            return []

    # 2. æ–°å¢åˆ é™¤æ–¹æ³•
    def delete_memory_by_ids(self, id_list):
        """æ ¹æ® ID åˆ—è¡¨åˆ é™¤è®°å¿†"""
        if not self.memory_collection or not id_list: return

        try:
            # Milvus åˆ é™¤è¡¨è¾¾å¼: "id in [123, 456]"
            expr = f"id in {id_list}"
            self.memory_collection.delete(expr)
            self.memory_collection.flush()  # ç¡®ä¿åˆ é™¤ç«‹å³ç”Ÿæ•ˆ
            print(f"ğŸ—‘ï¸ [Milvus] å·²åˆ é™¤è¿‡æœŸè®°å¿† ID: {id_list}")
        except Exception as e:
            print(f"âŒ Milvus åˆ é™¤å¤±è´¥: {e}")


if __name__ == '__main__':
    milvus_instance = MilvusClass()
    milvus_instance.connect_milvus()
    # milvus_instance.deleteMilvus("MilVus_test")
    milvus_instance.Batch_insert_food(r"D:\ASR-LLM-TTS-master\ASR-LLM-TTS-master\food_category.txt", one_bulk=100)