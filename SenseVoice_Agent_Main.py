# filename: agent_main.py
import cv2
import pyaudio
import wave
import threading
import numpy as np
import time
from queue import Queue
import webrtcvad
import os
import asyncio
import pygame
import edge_tts
from funasr import AutoModel
from modelscope.pipelines import pipeline
from pypinyin import pinyin, Style
import re

# --- å¯¼å…¥æˆ‘ä»¬çš„å¤§è„‘ ---
from SenseVoice_Agent_Brain import SmartAgentBrain

# --- é…ç½® ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
AUDIO_RATE = 16000
AUDIO_CHANNELS = 1
CHUNK = 1024
VAD_MODE = 3
OUTPUT_DIR = "./output"
NO_SPEECH_THRESHOLD = 1
folder_path = "./Test_Agent/"

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(folder_path, exist_ok=True)

# å…¨å±€å˜é‡
audio_queue = Queue()
recording_active = True
segments_to_save = []
last_active_time = time.time()
last_vad_end_time = 0
audio_file_count = 0

# --- KWS & å£°çº¹é…ç½® ---
set_KWS = "xiao ming tong xue"  # å”¤é†’è¯æ‹¼éŸ³
flag_KWS = 0
flag_KWS_used = 1  # æ˜¯å¦å¼€å¯å”¤é†’è¯
flag_sv_used = 1  # æ˜¯å¦å¼€å¯å£°çº¹
flag_sv_enroll = 0  # æ˜¯å¦å¤„äºæ³¨å†Œæ¨¡å¼
thred_sv = 0.30  # å£°çº¹é˜ˆå€¼

is_speaking = False  # æ˜¯å¦æ­£åœ¨æ’­æ”¾è¯­éŸ³
is_processing = False  # æ˜¯å¦æ­£åœ¨å¤„ç†æ¨ç†ï¼ˆASR+LLM+TTSæ•´ä¸ªæµç¨‹ï¼‰

# å£°çº¹è·¯å¾„
set_SV_enroll = r'.\SpeakerVerification_DIR\enroll_wav\\'

# --- åˆå§‹åŒ–æ¨¡å‹ ---
print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·ç¨å€™...")

# 1. åˆå§‹åŒ– VAD
vad = webrtcvad.Vad()
vad.set_mode(VAD_MODE)

# 2. åˆå§‹åŒ– SenseVoice (ASR)
# è¯·ç¡®ä¿ä½ çš„æ¨¡å‹è·¯å¾„æ­£ç¡®ï¼Œæˆ–è€…ä½¿ç”¨ modelscope è‡ªåŠ¨ä¸‹è½½çš„è·¯å¾„
model_dir = r"D:\ASR-LLM-TTS-master\ASR-LLM-TTS-master\ASR"
model_senceVoice = AutoModel(model=model_dir, trust_remote_code=True, device="cuda:0")

# 3. åˆå§‹åŒ– CAM++ (å£°çº¹)
sv_pipeline = pipeline(
    task='speaker-verification',
    model='D:\ASR-LLM-TTS-master\ASR-LLM-TTS-master\iic\CAM++',
    model_revision='v1.0.0',
    device="cuda:0"
)

# 4. åˆå§‹åŒ– Agent å¤§è„‘ (è¿æ¥ Milvus å’Œ LLM)
agent_brain = SmartAgentBrain()

print(">>> æ¨¡å‹åŠ è½½å®Œæˆï¼ç³»ç»Ÿå¯åŠ¨ï¼ <<<")


# --- è¾…åŠ©å‡½æ•° ---
def extract_pinyin(input_string):
    chinese_chars = re.findall(r'[\u4e00-\u9fa5]', input_string)
    chinese_text = ''.join(chinese_chars)
    pinyin_result = pinyin(chinese_text, style=Style.NORMAL)
    return ' '.join([item[0] for item in pinyin_result])


def play_audio(file_path):
    try:
        pygame.mixer.init()
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
        pygame.mixer.quit()
    except Exception as e:
        print(f"æ’­æ”¾å¤±è´¥: {e}")


async def text_to_speech(text, output_file):
    """ä½¿ç”¨ Edge TTS ç”Ÿæˆè¯­éŸ³"""
    voice = "zh-CN-XiaoyiNeural"
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)


def system_speak(text):
    """åŒæ­¥åŒ…è£…çš„ TTS æ’­æ”¾å‡½æ•°"""
    global audio_file_count, is_speaking, segments_to_save

    is_speaking = True
    segments_to_save.clear() # æ¸…ç©ºä¹‹å‰çš„ç¼“å­˜ï¼Œé¿å…å½•å…¥æ’­æŠ¥å£°éŸ³
    print(f"ğŸ¤– Agent: {text}")
    audio_file_count += 1
    filename = os.path.join(folder_path, f"reply_{audio_file_count}.mp3")
    asyncio.run(text_to_speech(text, filename))
    play_audio(filename)

    time.sleep(0.3)
    is_speaking = False


# --- æ ¸å¿ƒæ¨ç†çº¿ç¨‹ ---
def Inference(audio_path):
    global flag_sv_enroll, flag_KWS, flag_KWS_used, flag_sv_used, set_SV_enroll, is_processing, segments_to_save

    is_processing = True  # å¼€å§‹å¤„ç†ï¼Œæš‚åœå½•éŸ³
    segments_to_save.clear()
    try:
        # 0. æ£€æŸ¥å£°çº¹æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º (åˆæ¬¡è¿è¡Œé€»è¾‘)
        if flag_sv_used and not os.path.exists(os.path.join(set_SV_enroll, "enroll_0.wav")):
            print("æœªæ£€æµ‹åˆ°å£°çº¹ï¼Œè¿›å…¥æ³¨å†Œæ¨¡å¼...")
            system_speak("è¯·å…ˆè¯´ä¸€å¥è¯æ³¨å†Œå£°çº¹ï¼Œéœ€è¶…è¿‡ä¸‰ç§’å“¦ã€‚")
            flag_sv_enroll = 1
            return

        # 1. ASR è¯­éŸ³è¯†åˆ«
        try:
            res = model_senceVoice.generate(input=audio_path, cache={}, language="auto", use_itn=False)
            raw_text = res[0]['text'].split(">")[-1].strip()
            pinyin_text = extract_pinyin(raw_text)
            print(f"ğŸ‘‚ å¬åˆ°: {raw_text} (æ‹¼éŸ³: {pinyin_text})")
        except Exception as e:
            print(f"ASR Error: {e}")
            return

        if not raw_text: return

        # 2. å”¤é†’è¯æ£€æµ‹ (KWS)
        if flag_KWS_used:
            if set_KWS in pinyin_text:
                print(">>> å”¤é†’è¯åŒ¹é…æˆåŠŸï¼")
                flag_KWS = 1
                # å”¤é†’æˆåŠŸ, æ’­æŠ¥
                system_speak("æˆ‘åœ¨å‘¢, ä¸»äºº!")
                return
            else:
                # å¦‚æœæ²¡å”¤é†’ï¼Œç›´æ¥å¿½ç•¥
                if not flag_KWS:
                    print("æœªå”¤é†’...")
                    return

        # 3. å£°çº¹éªŒè¯ (SV)
        if flag_sv_used:
            try:
                enroll_path = os.path.join(set_SV_enroll, "enroll_0.wav")
                score = sv_pipeline([enroll_path, audio_path])
                print(f"ğŸ” å£°çº¹å¾—åˆ†: {score['score']}")

                if score['score'] < thred_sv:
                    system_speak("å£°çº¹éªŒè¯å¤±è´¥ï¼Œæˆ‘ä¸èƒ½å¬ä½ çš„æŒ‡ä»¤ã€‚")
                    flag_KWS = 0  # é‡ç½®å”¤é†’
                    return
            except Exception as e:
                print(f"SV Error: {e}")
                return

        # 4. è°ƒç”¨ Agent å¤§è„‘å¤„ç† (æ ¸å¿ƒç»“åˆç‚¹)
        # ä½¿ç”¨ asyncio.run åœ¨åŒæ­¥çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥é€»è¾‘
        reply = asyncio.run(agent_brain.process_user_query(raw_text))

        # 5. æ’­æŠ¥ç»“æœ
        system_speak(reply)
        pass
    finally:
        is_processing = False  # å¤„ç†å®Œæˆï¼Œæ¢å¤å½•éŸ³

    # äº¤äº’å®Œæˆåï¼Œå¯ä»¥é€‰æ‹©é‡ç½®å”¤é†’çŠ¶æ€ (éœ€å†æ¬¡å”¤é†’)ï¼Œæˆ–è€…ä¿æŒå”¤é†’
    # flag_KWS = 0


# --- å½•éŸ³çº¿ç¨‹ ---
def audio_recorder():
    global recording_active, last_active_time, segments_to_save, last_vad_end_time, audio_file_count, flag_sv_enroll

    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=AUDIO_CHANNELS, rate=AUDIO_RATE, input=True,
                    frames_per_buffer=CHUNK)
    audio_buffer = []

    print("ğŸ¤ éº¦å…‹é£ç›‘å¬ä¸­...")

    while recording_active:
        data = stream.read(CHUNK)
        audio_buffer.append(data)

        # æ¯ 0.5 ç§’æ£€æµ‹ VAD
        if len(audio_buffer) * CHUNK / AUDIO_RATE >= 0.5:
            raw_audio = b''.join(audio_buffer)
            # ç®€å• VAD æ£€æµ‹
            is_speech = False
            step = int(AUDIO_RATE * 0.02)
            speech_frames = 0
            for i in range(0, len(raw_audio), step):
                chunk = raw_audio[i:i + step]
                if len(chunk) == step and vad.is_speech(chunk, AUDIO_RATE):
                    speech_frames += 1
            if speech_frames > 5: is_speech = True

            if is_speech:
                # æ­£åœ¨å¤„ç†æˆ–æ’­æŠ¥æ—¶ä¸è®°å½•è¯­éŸ³æ®µ
                if not is_speaking and not is_processing:
                    last_active_time = time.time()
                    segments_to_save.append((raw_audio, time.time()))

            audio_buffer = []

        # åˆ¤å®šå¥å­ç»“æŸ (é™éŸ³è¶…æ—¶)
        if time.time() - last_active_time > NO_SPEECH_THRESHOLD and segments_to_save:

            # æ­£åœ¨æ’­æŠ¥ï¼Œè·³è¿‡å¤„ç†å¹¶æ¸…ç©ºç¼“å­˜
            if is_speaking or is_processing:
                segments_to_save.clear()
                continue
            # ä¿å­˜å¹¶æ¨ç†
            audio_file_count += 1

            # å¤„ç†å£°çº¹æ³¨å†Œçš„ç‰¹æ®Šé€»è¾‘
            save_path = f"{OUTPUT_DIR}/audio_tmp.wav"
            if flag_sv_enroll:
                os.makedirs(set_SV_enroll, exist_ok=True)
                save_path = os.path.join(set_SV_enroll, "enroll_0.wav")

            # å†™å…¥æ–‡ä»¶
            wf = wave.open(save_path, 'wb')
            wf.setnchannels(AUDIO_CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(AUDIO_RATE)
            wf.writeframes(b''.join([seg[0] for seg in segments_to_save]))
            wf.close()

            segments_to_save.clear()  # æ¸…ç©ºç¼“å­˜

            if flag_sv_enroll:
                print("å£°çº¹æ³¨å†Œæ–‡ä»¶å·²ä¿å­˜ã€‚")
                flag_sv_enroll = 0
                system_speak("å£°çº¹æ³¨å†ŒæˆåŠŸï¼ç°åœ¨å¯ä»¥å«æˆ‘äº†ã€‚")
            else:
                # å¼€å¯æ–°çº¿ç¨‹æ¨ç†ï¼Œé¿å…é˜»å¡å½•éŸ³
                t = threading.Thread(target=Inference, args=(save_path,))
                t.start()

    stream.stop_stream()
    stream.close()
    p.terminate()


if __name__ == "__main__":
    try:
        t_rec = threading.Thread(target=audio_recorder)
        t_rec.start()

        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        recording_active = False