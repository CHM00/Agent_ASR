import pyaudio
import wave
import threading
import numpy as np
import time
import queue  # æ ‡å‡†çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
import os
import asyncio
import pygame
import edge_tts
import glob
import re
import webrtcvad
from pypinyin import pinyin, Style

from SenseVoice_Agent_Brain import SmartAgentBrain
from SpeakerManager import SpeakerManager
import torchaudio
import pyttsx3

# --- é…ç½® ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
AUDIO_RATE = 16000
AUDIO_CHANNELS = 1
CHUNK = 1024
VAD_MODE = 3
OUTPUT_DIR = "./output"
NO_SPEECH_THRESHOLD = 0.5  # é™éŸ³é˜ˆå€¼ä»1->0.5sï¼Œé€‚åˆæ›´å¿«çš„äº¤äº’
folder_path = "./Test_Agent/"

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(folder_path, exist_ok=True)

# --- å…¨å±€çŠ¶æ€ ---
# çº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºä»å½•éŸ³çº¿ç¨‹ä¼ é€’éŸ³é¢‘è·¯å¾„åˆ°å¼‚æ­¥ä¸»å¾ªç¯
audio_task_queue = queue.Queue()

# å¼‚æ­¥é˜Ÿåˆ—ï¼Œç”¨äº LLM äº§å‡ºæ–‡æœ¬ä¼ ç»™ TTS
tts_text_queue = asyncio.Queue()

recording_active = True
segments_to_save = []
last_active_time = time.time()
audio_file_count = 0

# çŠ¶æ€æ ‡å¿—
is_speaking = False  # æ­£åœ¨æ’­æ”¾éŸ³é¢‘
is_processing = False  # æ­£åœ¨è¿›è¡Œ AI æ¨ç†

# --- KWS & å£°çº¹é…ç½® ---
set_KWS = "xiao ming tong xue"
flag_KWS = 0
flag_KWS_used = 1
flag_sv_used = 1
flag_sv_enroll = 0
thred_sv = 0.30
set_SV_enroll = r'.\SpeakerVerification_DIR\users\\'
temp_register_name = ""

# --- åˆå§‹åŒ–æ¨¡å‹ ---
print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·ç¨å€™...")
vad = webrtcvad.Vad()
vad.set_mode(VAD_MODE)

# åˆå§‹åŒ–å¤§è„‘
agent_brain = SmartAgentBrain()

model_senceVoice = agent_brain.local_model.funasr_model
sv_pipeline = agent_brain.local_model.CAM_model

spk_manager = SpeakerManager(set_SV_enroll, sv_pipeline, threshold=0.35)
# è·å– CosyVoice å®ä¾‹
cosyvoice_model = agent_brain.local_model.cosyvoice_model

# --- é¢„ç”Ÿæˆ/åŠ è½½å”¤é†’å›å¤éŸ³é¢‘ ---
WAKEUP_FILE = os.path.join(folder_path, "wakeup_reply.mp3")

# å¦‚æœæœ¬åœ°æ²¡æœ‰è¿™ä¸ªæ–‡ä»¶ï¼Œå°±ç”Ÿæˆä¸€ä¸ª
if not os.path.exists(WAKEUP_FILE):
    print("æ­£åœ¨é¢„ç”Ÿæˆå”¤é†’éŸ³é¢‘...")
    # è¿™é‡Œç”¨åŒæ­¥æ–¹å¼ç”Ÿæˆä¸€æ¬¡å³å¯ï¼Œå› ä¸ºæ˜¯åœ¨å¯åŠ¨é˜¶æ®µ
    async def gen_wakeup():
        communicate = edge_tts.Communicate("æˆ‘åœ¨å‘¢ï¼", "zh-CN-XiaoyiNeural")
        await communicate.save(WAKEUP_FILE)
    asyncio.run(gen_wakeup())

# å…¨å±€åˆå§‹åŒ– pygame mixer
pygame.mixer.init()

# print(">>> æ¨¡å‹åŠ è½½å®Œæˆï¼ç³»ç»Ÿå¯åŠ¨ (æµå¼æ¨¡å¼)ï¼ <<<")
print(">>> æ¨¡å‹åŠ è½½å®Œæˆï¼ç³»ç»Ÿå¯åŠ¨ (å…¨æœ¬åœ°æµå¼æ¨¡å¼)ï¼ <<<")

# --- è¾…åŠ©å‡½æ•° ---
def extract_pinyin(input_string):
    chinese_chars = re.findall(r'[\u4e00-\u9fa5]', input_string)
    chinese_text = ''.join(chinese_chars)
    pinyin_result = pinyin(chinese_text, style=Style.NORMAL)
    return ' '.join([item[0] for item in pinyin_result])


def play_audio_sync(file_path):
    """
    åŒæ­¥æ’­æ”¾éŸ³é¢‘ï¼ˆä¼šé˜»å¡è°ƒç”¨å®ƒçš„çº¿ç¨‹/åç¨‹ï¼‰ï¼Œç”¨äºç¡®ä¿ TTS å¥å­æŒ‰é¡ºåºè¯´å®Œ
    """
    try:
        # pygame.mixer.init()
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)  # é™ä½CPUå ç”¨
        # pygame.mixer.quit()
    except Exception as e:
        print(f"æ’­æ”¾å¤±è´¥: {e}")


async def async_play_audio(file_path):
    """å¼‚æ­¥åŒ…è£…æ’­æ”¾ï¼Œåˆ©ç”¨ executor é¿å…é˜»å¡äº‹ä»¶å¾ªç¯"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, play_audio_sync, file_path)


# --- TTS æ¶ˆè´¹è€…ï¼ˆEdgeTTS, CosyVoice, pyttsx3ï¼‰ ---
def pyttsx3_synthesis_sync(text, filename):
    """
    åŒæ­¥åˆæˆå‡½æ•°ï¼šæ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°åˆå§‹åŒ– engineï¼Œé¿å… COM å†²çª
    """
    import pyttsx3
    try:
        # 1. æ¯æ¬¡éƒ½é‡æ–°åˆå§‹åŒ– (å…³é”®ï¼)
        engine = pyttsx3.init()

        # 2. è®¾ç½®å±æ€§ (è¯­é€Ÿã€éŸ³è‰²)
        rate = engine.getProperty('rate')
        engine.setProperty('rate', rate - 10)  # ç¨å¾®è°ƒæ…¢

        # å°è¯•æ‰¾ä¸­æ–‡å‘éŸ³äºº
        voices = engine.getProperty('voices')
        for v in voices:
            if "Chinese" in v.name or "Huihui" in v.name:
                engine.setProperty('voice', v.id)
                break

        # 3. ä¿å­˜æ–‡ä»¶
        # æ³¨æ„ï¼šsave_to_file æ˜¯å°†å‘½ä»¤æ”¾å…¥é˜Ÿåˆ—
        engine.save_to_file(text, filename)

        # 4. æ‰§è¡Œå¹¶ç­‰å¾… (è¿™æ˜¯é˜»å¡çš„)
        engine.runAndWait()

        # 5. é”€æ¯å¼•æ“ (è™½ç„¶ Python ä¼šè‡ªåŠ¨å›æ”¶ï¼Œä½†åœ¨ COM ä¸­æ˜¾å¼æ¸…ç†æ›´å¥½)
        del engine
        return True
    except Exception as e:
        print(f"pyttsx3 å†…éƒ¨é”™è¯¯: {e}")
        return False


async def tts_consumer_worker():
    """
    åå°ä»»åŠ¡ï¼šä»é˜Ÿåˆ—å–æ–‡æœ¬ -> ç‹¬ç«‹çº¿ç¨‹è¿è¡Œ pyttsx3 -> pygame æ’­æ”¾
    """
    global is_speaking, audio_file_count

    while True:
        # ç­‰å¾…é˜Ÿåˆ—ä¸­æœ‰æ–‡å­—
        item = await tts_text_queue.get()
        if isinstance(item, tuple):
            text, t0_ref = item
        else:
            text, t0_ref = item, None

        # è¿‡æ»¤æ— æ•ˆæ–‡æœ¬
        if not text or len(text.strip()) < 1:
            tts_text_queue.task_done()
            continue

        is_speaking = True
        segments_to_save.clear()  # é˜²æ­¢å½•å…¥è‡ªå·±å£°éŸ³

        try:
            audio_file_count += 1
            filename = os.path.join(folder_path, f"stream_{audio_file_count}.wav")

            print(f"pyttsx3 æ­£åœ¨åˆæˆ: {text}")

            # æ”¾å…¥çº¿ç¨‹æ± è¿è¡Œ
            loop = asyncio.get_event_loop()

            # run_in_executor ä¼šåœ¨ç‹¬ç«‹çº¿ç¨‹è¿è¡Œ pyttsx3_synthesis_sync
            # è¿™æ · pyttsx3 çš„é˜»å¡å¾ªç¯å°±ä¸ä¼šå¡æ­»ä¸»ç¨‹åºçš„ asyncio å¾ªç¯
            success = await loop.run_in_executor(None, pyttsx3_synthesis_sync, text, filename)

            if success and os.path.exists(filename):
                # æ’­æ”¾å‰æ‰“ç‚¹
                t3_play = time.time()
                if t0_ref:
                    latency = t3_play - t0_ref
                    print(f"T3-pyttsx3 å“åº”å»¶è¿Ÿ: {latency:.3f}s")

                # æ’­æ”¾
                await async_play_audio(filename)

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(filename)
                except:
                    pass
            else:
                print("TTS åˆæˆå¤±è´¥æˆ–æ–‡ä»¶æœªç”Ÿæˆ")

        except Exception as e:
            print(f"TTS/æ’­æ”¾å‡ºé”™: {e}")
        finally:
            tts_text_queue.task_done()
            if tts_text_queue.empty():
                is_speaking = False

'''
    ä½¿ç”¨CosyVoice åˆæˆ
'''
async def tts_consumer_worker():
    """
    åå°ä»»åŠ¡ï¼šä¸æ–­ä» tts_text_queue è·å–æ–‡å­— -> CosyVoice åˆæˆ -> æ’­æ”¾
    """
    global is_speaking, audio_file_count

    while True:
        item = await tts_text_queue.get()
        if isinstance(item, tuple):
            text, t0_ref = item
        else:
            text, t0_ref = item, None

        # è¿‡æ»¤æ‰ç©ºçš„æˆ–è€…å¤ªçŸ­çš„æ–‡æœ¬ï¼Œé¿å…æŠ¥é”™
        if not text or len(text.strip()) < 1:
            tts_text_queue.task_done()
            continue

        is_speaking = True
        segments_to_save.clear()

        try:
            audio_file_count += 1
            # CosyVoice è¾“å‡ºæ˜¯ wav æ ¼å¼ï¼Œå»ºè®®ç”¨ .wav åç¼€
            filename = os.path.join(folder_path, f"stream_{audio_file_count}.wav")

            print(f"æ­£åœ¨åˆæˆ: {text}")

            # --- CosyVoice æ¨ç† (è¿™æ˜¯åŒæ­¥ä»£ç ï¼Œä¸”è€—æ—¶ï¼Œå¿…é¡»æ”¾å…¥çº¿ç¨‹æ± ) ---
            loop = asyncio.get_event_loop()

            # å®šä¹‰ä¸€ä¸ªåŒæ­¥å‡½æ•°æ¥æ‰§è¡Œæ¨ç†å’Œä¿å­˜
            def run_cosyvoice_sync(input_text, out_path):
                # stream=False: å’±ä»¬æ˜¯æŒ‰å¥å­è¿›æ¥çš„ï¼Œç›´æ¥ç”Ÿæˆæ•´å¥æ¯”æµå¼åˆ‡ç‰‡å¤„ç†ç®€å•ä¸”æ•ˆæœå¥½
                # 'ä¸­æ–‡å¥³' æ˜¯éŸ³è‰²åï¼Œä½ å¯ä»¥æ”¹æˆ 'ä¸­æ–‡ç”·' æˆ–å…¶ä»–
                model_output = cosyvoice_model.inference_sft(input_text, 'ä¸­æ–‡å¥³', stream=False)

                # éå†ç”Ÿæˆå™¨ (å…¶å®åªæœ‰ä¸€æ®µéŸ³é¢‘ï¼Œå› ä¸º stream=False)
                for i, j in enumerate(model_output):
                    # j['tts_speech'] æ˜¯ tensor, é‡‡æ ·ç‡é€šå¸¸æ˜¯ 22050
                    torchaudio.save(out_path, j['tts_speech'], 22050)
                    return True  # ç”ŸæˆæˆåŠŸ
                return False

            # åœ¨ executor ä¸­è¿è¡Œï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
            success = await loop.run_in_executor(None, run_cosyvoice_sync, text, filename)

            if success:
                # æ’­æ”¾å‰æ‰“ç‚¹
                t3_play = time.time()
                if t0_ref:
                    latency = t3_play - t0_ref
                    print(f"T3-CosyVoice å“åº”å»¶è¿Ÿ: {latency:.3f}s")

                # æ’­æ”¾
                await async_play_audio(filename)

                # åˆ é™¤
                try:
                    os.remove(filename)
                except:
                    pass
            else:
                print("CosyVoice åˆæˆæœªè¿”å›æ•°æ®")

        except Exception as e:
            print(f"TTS/æ’­æ”¾å‡ºé”™: {e}")
        finally:
            tts_text_queue.task_done()
            if tts_text_queue.empty():
                is_speaking = False

'''
ä½¿ç”¨ EdgeTTS åˆæˆ
'''
async def tts_consumer_worker():
    """
    åå°ä»»åŠ¡ï¼šä¸æ–­ä» tts_text_queue è·å–æ–‡å­— -> åˆæˆ -> æ’­æ”¾
    å®ç°äº†â€œè¾¹ç”Ÿæˆè¾¹æ’­æ”¾â€çš„æ•ˆæœï¼Œä¸”ä¿è¯å¥å­é¡ºåº
    """
    global is_speaking, audio_file_count

    while True:
        # ç­‰å¾…é˜Ÿåˆ—ä¸­æœ‰æ–‡å­—
        item = await tts_text_queue.get()
        if isinstance(item, tuple):
            text, t0_ref = item
        else:
            text, t0_ref = item, None

        # text = await tts_text_queue.get()

        # æ ‡è®°æ­£åœ¨è¯´è¯
        is_speaking = True
        # æ¸…ç©ºå½•éŸ³ç¼“å­˜ï¼Œé˜²æ­¢æŠŠè‡ªå·±è¯´è¯å½•è¿›å»
        segments_to_save.clear()

        try:
            audio_file_count += 1
            filename = os.path.join(folder_path, f"stream_{audio_file_count}.mp3")

            print(f"æ­£åœ¨æ’­æŠ¥: {text}")

            # 1. ç”Ÿæˆè¯­éŸ³ Edge-TTS æ˜¯å¼‚æ­¥çš„
            communicate = edge_tts.Communicate(text, "zh-CN-XiaoyiNeural")
            await communicate.save(filename)

            # æ’­æ”¾å‰æ‰“ç‚¹
            t3_play = time.time()  # <---ã€åŸ‹ç‚¹ T3ã€‘å¼€å§‹æ’­æ”¾
            if t0_ref:
                latency = t3_play - t0_ref
                print(f"T3-é¦–å­—éŸ³é¢‘å“åº”å»¶è¿Ÿï¼ï¼ï¼: {latency:.3f}s")

            # 2. æ’­æ”¾è¯­éŸ³ (å¿…é¡»awaitæ’­æ”¾å®Œæˆï¼Œå¦åˆ™ä¸‹ä¸€å¥ä¼šé‡å )
            await async_play_audio(filename)

            # 3. åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(filename)
            except:
                pass

        except Exception as e:
            print(f"TTS/æ’­æ”¾å‡ºé”™: {e}")
        finally:
            tts_text_queue.task_done()

            # å¦‚æœé˜Ÿåˆ—ç©ºäº†ï¼Œè¯´æ˜è¿™ä¸€è½®è¯´è¯ç»“æŸ
            if tts_text_queue.empty():
                is_speaking = False


# --- æ ¸å¿ƒä»»åŠ¡ï¼šæ¨ç†è°ƒåº¦å™¨ ---
async def inference_scheduler():
    """
    ä¸»å¾ªç¯ï¼šç›‘å¬å½•éŸ³çº¿ç¨‹å‘æ¥çš„éŸ³é¢‘è·¯å¾„ -> æ‰§è¡Œ ASR -> æ‰§è¡Œ LLM -> æ¨é€ç»™ TTS
    """
    global is_processing, flag_KWS, flag_sv_enroll, temp_register_name

    while True:
        # 1. éé˜»å¡æ–¹å¼æ£€æŸ¥ queue.Queue
        try:
            # ä»é˜Ÿåˆ—è·å–å½•éŸ³æ–‡ä»¶è·¯å¾„, æ²¡å–åˆ°å°±è·³è¿‡
            audio_path = audio_task_queue.get_nowait()
            t0_start = time.time()  # <---ã€åŸ‹ç‚¹ T0ã€‘å¼€å§‹å¤„ç†
            print(f"T0-å¼€å§‹å¤„ç†: {t0_start}")
        except queue.Empty:
            await asyncio.sleep(0.1)
            continue

        is_processing = True
        segments_to_save.clear()

        try:
            # --- 0. é¦–æ¬¡è¿è¡Œæ³¨å†Œé€»è¾‘ ---
            existing_users = glob.glob(os.path.join(set_SV_enroll, "*.wav"))
            if flag_sv_used and not existing_users and not flag_sv_enroll:
                print("åˆæ¬¡è§é¢ï¼Œè¯·æ³¨å†Œã€‚")
                await tts_text_queue.put("æ¬¢è¿ä½¿ç”¨ï¼Œè¯·è¯´ä¸€å¥è¯æ³¨å†Œå£°çº¹ã€‚")
                temp_register_name = "ä¸»äºº"
                flag_sv_enroll = 1
                audio_task_queue.task_done()
                is_processing = False
                continue

            # --- 1. ASR è¯†åˆ« (åŒæ­¥æ¨¡å‹éœ€æ”¾å…¥ executor è¿è¡Œé˜²æ­¢å¡æ­») ---
            loop = asyncio.get_event_loop()
            raw_text = await loop.run_in_executor(None, run_asr, audio_path)
            t1_asr = time.time()  # <---ã€åŸ‹ç‚¹ T1ã€‘ASRç»“æŸ
            print(f"T1-ASRè€—æ—¶: {t1_asr - t0_start:.3f}s")
            if not raw_text:
                is_processing = False
                continue

            pinyin_text = extract_pinyin(raw_text)
            print(f"å¬åˆ°: {raw_text}")

            # --- 2. å”¤é†’è¯é€»è¾‘ ---
            if flag_KWS_used:
                if set_KWS in pinyin_text:
                    print(">>> å”¤é†’æˆåŠŸï¼")
                    flag_KWS = 1
                    print("æé€Ÿå“åº”: æˆ‘åœ¨å‘¢ï¼")
                    await async_play_audio(WAKEUP_FILE)

                    # await tts_text_queue.put("æˆ‘åœ¨å‘¢ï¼")  # æ”¾å…¥æ’­æ”¾é˜Ÿåˆ—
                    is_processing = False  # å”¤é†’è¯ä¸éœ€è¦è¿›LLM
                    continue
                else:
                    if not flag_KWS:
                        # æœªå”¤é†’çŠ¶æ€ï¼Œå¿½ç•¥
                        is_processing = False
                        continue

            # --- 3. å£°çº¹è¯†åˆ« ---
            current_user_id = "Guest"
            if flag_sv_used:
                user, score = spk_manager.identify(audio_path)
                if user == "Unknown":
                    await tts_text_queue.put("æŠ±æ­‰ï¼Œæˆ‘æ²¡å¬å‡ºä½ æ˜¯è°ã€‚")
                    flag_KWS = 0
                    is_processing = False
                    continue
                current_user_id = user

            # --- 4. LLM æµå¼äº¤äº’ ---
            first_sentence_flag = True  # æ ‡è®°æ˜¯å¦æ˜¯ç¬¬ä¸€å¥
            # è°ƒç”¨ Brain çš„å¼‚æ­¥ç”Ÿæˆå™¨
            async for sentence in agent_brain.process_user_query(raw_text, current_user_id):

                # æ£€æŸ¥ç‰¹æ®ŠæŒ‡ä»¤
                if sentence.startswith("ACTION_REGISTER:"):
                    target_name = sentence.split(":")[1]
                    if target_name == "Unknown_User":
                        await tts_text_queue.put("è¯·é—®æ€ä¹ˆç§°å‘¼æ‚¨ï¼Ÿ")
                    else:
                        temp_register_name = target_name
                        flag_sv_enroll = 1
                        await tts_text_queue.put(f"å‡†å¤‡å½•å…¥{target_name}çš„å£°çº¹ï¼Œè¯·å¬åˆ°æ»´å£°åè¯´è¯ã€‚")
                    break  # åœæ­¢åç»­ç”Ÿæˆ

                # æ™®é€šæ–‡æœ¬ -> æ”¾å…¥æ’­æ”¾é˜Ÿåˆ—
                if sentence.strip():
                    if first_sentence_flag:
                        t2_llm_first = time.time()
                        print(f"T2-LLMé¦–å¥ç”Ÿæˆè€—æ—¶: {t2_llm_first - t1_asr:.3f}s")
                        print(f"é¦–å¥å†…å®¹: {sentence}")
                        # å°† t0 ä¼ ç»™ TTS é˜Ÿåˆ—ä»¥ä¾¿è®¡ç®—æ€»å»¶è¿Ÿ

                    await tts_text_queue.put((sentence, t0_start if first_sentence_flag else None))
                    first_sentence_flag = False
                    # await tts_text_queue.put(sentence)

        except Exception as e:
            print(f"Inference Error: {e}")
        finally:
            is_processing = False
            # åˆ é™¤å½•éŸ³ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(audio_path)
            except:
                pass


def run_asr(audio_path):
    """å°è£… ASR ä¸ºç‹¬ç«‹å‡½æ•°"""
    try:
        res = model_senceVoice.generate(input=audio_path, cache={}, language="auto", use_itn=False)
        return res[0]['text'].split(">")[-1].strip()
    except:
        return ""


# --- å½•éŸ³çº¿ç¨‹ (ä¿æŒç‹¬ç«‹) ---
def audio_recorder_thread():
    global recording_active, last_active_time, segments_to_save, audio_file_count, flag_sv_enroll, temp_register_name

    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=AUDIO_CHANNELS, rate=AUDIO_RATE, input=True,
                    frames_per_buffer=CHUNK)
    audio_buffer = []

    print("ğŸ™ï¸ éº¦å…‹é£ç›‘å¬ä¸­...")

    while recording_active:
        data = stream.read(CHUNK)
        audio_buffer.append(data)

        # VAD æ£€æµ‹é€»è¾‘ (æ¯0.5ç§’)
        if len(audio_buffer) * CHUNK / AUDIO_RATE >= 0.5:
            raw_audio = b''.join(audio_buffer)
            is_speech = is_speech_detected(raw_audio)

            if is_speech:
                # åªæœ‰å½“æœºå™¨äººæ²¡åœ¨è¯´è¯ã€ä¹Ÿæ²¡åœ¨æ€è€ƒæ—¶ï¼Œæ‰å½•éŸ³
                if not is_speaking and not is_processing:
                    last_active_time = time.time()
                    segments_to_save.append((raw_audio, time.time()))
                else:
                    # å¦‚æœæœºå™¨äººåœ¨è¯´è¯ï¼Œæ¸…ç©ºbufferé˜²æ­¢å½•å…¥å›å£°
                    pass

            audio_buffer = []  # é‡ç½®buffer

        # åˆ¤å®šå¥å­ç»“æŸ
        if time.time() - last_active_time > NO_SPEECH_THRESHOLD and segments_to_save:
            # å†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢æˆªæ–­æ’­æŠ¥
            if is_speaking or is_processing:
                segments_to_save.clear()
                continue

            # ä¿å­˜é€»è¾‘
            if flag_sv_enroll:
                handle_enrollment()
            else:
                # æ™®é€šå¯¹è¯ -> ä¿å­˜ä¸´æ—¶æ–‡ä»¶ -> æ”¾å…¥é˜Ÿåˆ—
                save_temp_and_queue()

    stream.stop_stream()
    stream.close()
    p.terminate()


def is_speech_detected(raw_audio):
    """VAD æ£€æµ‹å°è£…"""
    step = int(AUDIO_RATE * 0.02)
    frames = 0
    for i in range(0, len(raw_audio), step):
        chunk = raw_audio[i:i + step]
        if len(chunk) == step and vad.is_speech(chunk, AUDIO_RATE):
            frames += 1
    return frames > 5


def save_temp_and_queue():
    """ä¿å­˜å¯¹è¯å½•éŸ³å¹¶æ”¾å…¥å¤„ç†é˜Ÿåˆ—"""
    global segments_to_save
    temp_path = f"{OUTPUT_DIR}/rec_{int(time.time())}.wav"
    write_wav(temp_path, segments_to_save)
    segments_to_save.clear()

    # æ”¾å…¥é˜Ÿåˆ—ï¼Œé€šçŸ¥ä¸»çº¿ç¨‹å¤„ç†
    audio_task_queue.put(temp_path)


def handle_enrollment():
    """å¤„ç†å£°çº¹æ³¨å†Œé€»è¾‘"""
    global flag_sv_enroll, temp_register_name, segments_to_save

    final_name = f"{temp_register_name}.wav" if temp_register_name else f"User_{int(time.time())}.wav"
    save_path = os.path.join(set_SV_enroll, final_name)

    write_wav(save_path, segments_to_save)
    segments_to_save.clear()

    print(f"å£°çº¹å·²æ³¨å†Œ: {final_name}")
    spk_manager.refresh_speakers()
    flag_sv_enroll = 0
    temp_register_name = ""

    # ç”±äºæˆ‘ä»¬åœ¨å­çº¿ç¨‹ï¼Œä¸èƒ½ç›´æ¥è°ƒ async å‡½æ•°ï¼Œä½¿ç”¨ run_coroutine_threadsafe
    print("æ³¨å†Œå®Œæˆï¼Œè¯·ç»§ç»­å¯¹è¯ã€‚")


def write_wav(path, segments):
    wf = wave.open(path, 'wb')
    wf.setnchannels(AUDIO_CHANNELS)
    wf.setsampwidth(2)
    wf.setframerate(AUDIO_RATE)
    wf.writeframes(b''.join([seg[0] for seg in segments]))
    wf.close()


# --- ä¸»å…¥å£ ---
async def main_entry():
    # å¯åŠ¨ TTS æ¶ˆè´¹è€…ä»»åŠ¡
    tts_task = asyncio.create_task(tts_consumer_worker())

    # å¯åŠ¨ æ¨ç†è°ƒåº¦ä»»åŠ¡
    inference_task = asyncio.create_task(inference_scheduler())

    # å¯åŠ¨ å½•éŸ³çº¿ç¨‹
    rec_thread = threading.Thread(target=audio_recorder_thread, daemon=True)
    rec_thread.start()

    print("æ‰€æœ‰æœåŠ¡å·²å°±ç»ªï¼Œè¯·è¯´è¯...")

    # ç­‰å¾…ä»»åŠ¡
    await asyncio.gather(tts_task, inference_task)


if __name__ == "__main__":
    try:
        asyncio.run(main_entry())
    except KeyboardInterrupt:
        recording_active = False
        print("ç³»ç»Ÿé€€å‡º")